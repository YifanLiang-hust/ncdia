{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction The OpenHAIV framework primarily focuses on Open World Learing tasks and currently supports the following: \ud83c\udfaf Supervised Learning Supervised learning is one of the most commonly used machine learning algorithms. In the field of computer vision, tasks such as image classification typically rely on labeled data for training. Labeled data refers to paired input data and corresponding target outputs (labels). Through these pairs, the model learns the mapping from input to output. During training, the model continuously adjusts its internal parameters to minimize the gap between predictions and actual labels. A fundamental training framework should support supervised learning, and Openhaiv allows the use of different deep learning models, datasets, and flexible hyperparameter tuning. \ud83c\udf31 Incremental Learning Incremental learning is an advanced machine learning paradigm designed to address the issue of catastrophic forgetting in machine learning. Specifically, incremental learning enables models to learn new knowledge while retaining and optimizing previously acquired knowledge. Currently, mainstream incremental learning methods can be categorized into three types: regularization-based methods, experience replay-based methods, and parameter isolation-based methods. The Openhaiv framework currently supports multiple incremental learning algorithms, including ALICE, FACT, and SAVC, allowing users to select and adjust them based on task requirements. \ud83e\udde9 Few-Shot Learning Few-shot learning is a common scenario in deep learning, where models must learn and make inferences effectively with only a small number of samples. Specifically, few-shot learning uses a limited number of samples during training (typically 5\u201310 samples per class). The OpenHAIV framework currently supports few-shot learning, allowing users to define models, datasets, and the number of samples per class in the few-shot stage. Few-shot learning often employs methods such as contrastive learning and augmentation techniques, which are well-supported in Openhaiv. Additionally, the framework is highly extensible, enabling the integration of new few-shot learning methods. \ud83d\udea8 Out-of-Distribution Detection Out-of-distribution detection is the process of identifying whether data deviates from the known data distribution. On one hand, OOD detection ensures that models can make reliable judgments when encountering inputs different from known classes, thereby improving system robustness. On the other hand, OOD detection is a crucial component of incremental object recognition in open environments. The Openhaiv framework currently supports multiple OOD detection algorithms, allowing flexible adjustments for different domains and tasks. \ud83d\udd0d Novel Category Discovery Novel category discovery refers to identifying and discovering new categories in data without pre-existing labeled classes. Currently, novel category discovery typically employs unsupervised clustering algorithms in machine learning. Unsupervised clustering groups datasets into clusters, and Openhaiv supports the use of the K-Means clustering algorithm for novel category discovery. K-Means partitions data into K clusters, with each cluster represented by its centroid (the center point of the cluster). The algorithm iteratively updates centroids to minimize the within-cluster squared distances.","title":"Introduction"},{"location":"#introduction","text":"The OpenHAIV framework primarily focuses on Open World Learing tasks and currently supports the following:","title":"Introduction"},{"location":"#supervised-learning","text":"Supervised learning is one of the most commonly used machine learning algorithms. In the field of computer vision, tasks such as image classification typically rely on labeled data for training. Labeled data refers to paired input data and corresponding target outputs (labels). Through these pairs, the model learns the mapping from input to output. During training, the model continuously adjusts its internal parameters to minimize the gap between predictions and actual labels. A fundamental training framework should support supervised learning, and Openhaiv allows the use of different deep learning models, datasets, and flexible hyperparameter tuning.","title":"\ud83c\udfaf Supervised Learning"},{"location":"#incremental-learning","text":"Incremental learning is an advanced machine learning paradigm designed to address the issue of catastrophic forgetting in machine learning. Specifically, incremental learning enables models to learn new knowledge while retaining and optimizing previously acquired knowledge. Currently, mainstream incremental learning methods can be categorized into three types: regularization-based methods, experience replay-based methods, and parameter isolation-based methods. The Openhaiv framework currently supports multiple incremental learning algorithms, including ALICE, FACT, and SAVC, allowing users to select and adjust them based on task requirements.","title":"\ud83c\udf31 Incremental Learning"},{"location":"#few-shot-learning","text":"Few-shot learning is a common scenario in deep learning, where models must learn and make inferences effectively with only a small number of samples. Specifically, few-shot learning uses a limited number of samples during training (typically 5\u201310 samples per class). The OpenHAIV framework currently supports few-shot learning, allowing users to define models, datasets, and the number of samples per class in the few-shot stage. Few-shot learning often employs methods such as contrastive learning and augmentation techniques, which are well-supported in Openhaiv. Additionally, the framework is highly extensible, enabling the integration of new few-shot learning methods.","title":"\ud83e\udde9 Few-Shot Learning"},{"location":"#out-of-distribution-detection","text":"Out-of-distribution detection is the process of identifying whether data deviates from the known data distribution. On one hand, OOD detection ensures that models can make reliable judgments when encountering inputs different from known classes, thereby improving system robustness. On the other hand, OOD detection is a crucial component of incremental object recognition in open environments. The Openhaiv framework currently supports multiple OOD detection algorithms, allowing flexible adjustments for different domains and tasks.","title":"\ud83d\udea8 Out-of-Distribution Detection"},{"location":"#novel-category-discovery","text":"Novel category discovery refers to identifying and discovering new categories in data without pre-existing labeled classes. Currently, novel category discovery typically employs unsupervised clustering algorithms in machine learning. Unsupervised clustering groups datasets into clusters, and Openhaiv supports the use of the K-Means clustering algorithm for novel category discovery. K-Means partitions data into K clusters, with each cluster represented by its centroid (the center point of the cluster). The algorithm iteratively updates centroids to minimize the within-cluster squared distances.","title":"\ud83d\udd0d Novel Category Discovery"},{"location":"acknowledgment/","text":"\ud83d\ude4fAcknowledgement OpenOOD , an extensible codebase for out-of-distribution detection with Vision Models only. OpenOOD-VLM , an extensible codebase for out-of-distribution detection with both Vision Models and Vision-Language Models. PyCIL , an extensible codebase for incremental learning.","title":"Acknowledgment"},{"location":"acknowledgment/#acknowledgement","text":"OpenOOD , an extensible codebase for out-of-distribution detection with Vision Models only. OpenOOD-VLM , an extensible codebase for out-of-distribution detection with both Vision Models and Vision-Language Models. PyCIL , an extensible codebase for incremental learning.","title":"\ud83d\ude4fAcknowledgement"},{"location":"citation/","text":"\ud83d\udcd6Citation If you find our repository useful for your research, please consider citing these papers: @article{openhaiv2025, title={OpenHAIV:A Framework Towards Practical Open-World Learning}, author={Xiang Xiang, Qinhao Zhou, Zhuo Xu, Jing Ma, Jiaxin Dai, Yifan Liang, Hanlin Li}, journal={Journal Name}, year={2025}, volume={XX}, number={YY}, pages={ZZZ}, doi={10.xxxx/your-doi}, url={https://arxiv.org/abs/your-arxiv-id} }","title":"Citation"},{"location":"citation/#citation","text":"If you find our repository useful for your research, please consider citing these papers: @article{openhaiv2025, title={OpenHAIV:A Framework Towards Practical Open-World Learning}, author={Xiang Xiang, Qinhao Zhou, Zhuo Xu, Jing Ma, Jiaxin Dai, Yifan Liang, Hanlin Li}, journal={Journal Name}, year={2025}, volume={XX}, number={YY}, pages={ZZZ}, doi={10.xxxx/your-doi}, url={https://arxiv.org/abs/your-arxiv-id} }","title":"\ud83d\udcd6Citation"},{"location":"config/","text":"Configuration System The OpenHAIV framework uses a flexible YAML-based configuration system that allows users to easily define and modify various experimental parameters without changing the code. This document provides detailed information about the structure, usage, and major components of the configuration files. Configuration File Structure OpenHAIV configuration files follow a hierarchical structure, mainly divided into the following sections: Base Configuration : Defines basic parameters for experiments, such as random seed, device, output directory, etc. Trainer Configuration : Defines parameters for the training process Model Configuration : Defines model architecture and related parameters Algorithm Configuration : Defines specific algorithms and methods Data Loader Configuration : Defines datasets and data loading parameters Optimizer Configuration : Defines optimization algorithms and related parameters Scheduler Configuration : Defines learning rate scheduling strategies Configuration files can inherit from other configuration files through the _base_ field, enabling modular and reusable configurations. Configuration Modules in Detail config.algorithms Algorithm configurations define the specific algorithms and methods used in experiments, including: Supervised Learning Algorithms algorithm: type: StandardSL # Standard supervised learning Class-incremental Learning Algorithms algorithm: type: LwF # Learning without Forgetting # Algorithm-specific parameters temperature: 2.0 alpha: 1.0 Other supported class-incremental learning algorithms include: Finetune , Joint , iCaRL , EWC , BiC , WA , DER , Coil , FOSTER , SSRE , FeTrIL , MEMO , etc. Few-shot Class-incremental Learning Algorithms algorithm: type: SAVC # Few-shot class-incremental learning algorithm # Algorithm-specific parameters alpha: 1.0 beta: 0.1 Out-of-Distribution Detection Algorithms algorithm: type: MSP # Maximum Softmax Probability # or type: MLS # Maximum Logit Score # or type: MCM # Maximum Concept Matching Other supported out-of-distribution detection algorithms include: ODIN , VIM , MDS , DML , FDBD , GODIN , MCM , GL-MCM , etc. config.dataloader Data loader configurations define the datasets and data loading parameters used in experiments: _base_: configs/dataloader/OES/oes.yaml # Inherit base dataset configuration dataloader: train: dataset: type: OES # Dataset type root: /path/to/dataset # Dataset path split: train # Dataset split batch_size: 128 # Batch size num_workers: 4 # Number of data loading worker threads shuffle: True # Whether to shuffle data val: # Validation set configuration dataset: type: OES root: /path/to/dataset split: val batch_size: 128 num_workers: 4 shuffle: False Supported datasets include: OES , CIFAR10 , CIFAR100 , ImageNet , ImageNetR , CUB200 , Remote , Food101 , Caltech101 , etc. config.model Model configurations define the model architecture and related parameters used in experiments: model: type: ResNet18 # Model type # Or use a more complex definition type: ResNet_Base network: type: ResNet18 num_classes: 94 checkpoint: \"/path/to/checkpoint.pth\" # Pre-trained model path loss: CrossEntropyLoss # Loss function type Supported models include: - Standard CNN models: ResNet18 , ResNet34 , ResNet50 , ResNet101 - Vision-language models: CLIP-B/16 , CLIP-B/32 , RSCLIP-B/16 , RSCLIP-B/32 - Algorithm-specific models: AliceNET , CoOp , LoCoOp , SCT , DPM config.pipeline Pipeline configuration files integrate all of the above components into a complete experiment configuration, for example, a supervised learning pipeline configuration: _base_: configs/dataloader/OES/oes.yaml # Inherit data loader configuration trainer: type: PreTrainer # Trainer type max_epochs: 10 # Maximum training epochs algorithm: type: StandardSL # Algorithm type model: type: ResNet18 # Model type criterion: type: CrossEntropyLoss # Loss function optimizer: type: Adam # Optimizer lr: 0.0003 # Learning rate weight_decay: 0.0001 # Weight decay scheduler: type: Constant # Scheduler type seed: 0 # Random seed device: cuda # Device exp_name: exp # Experiment name work_dir: ./output/supervised/sl_oes_rn18 # Output directory How to Use Configurations Configuration files can be passed to the training script via command line: python ncdia/train.py --cfg configs/pipeline/supervised_learning/sl_oes_rn18.yaml --opts device='cuda:0' The --opts parameter allows overriding any parameter in the configuration file. Configuration Inheritance Mechanism OpenHAIV's configuration system supports composition based on inheritance, making configurations more modular and reusable: _base_: [ configs/dataloader/OES/oesfull.yaml, # Inherit data loader configuration configs/algorithms/ood_detection/dml.yaml, # Inherit algorithm configuration ] # Override or add specific parameters trainer: type: DetTrainer max_epochs: 10 model: type: ResNet_Base network: type: ResNet18 num_classes: 94 Through the inheritance mechanism, repetitive configurations can be avoided, improving the maintainability of configuration files. Configuration Best Practices Modular Configuration : Extract common configurations as base configuration files, and combine them through inheritance Use Relative Paths : Paths in configuration files should use paths relative to the project root directory when possible Comment Key Parameters : Add comments to important parameters to improve readability Parameter Tuning : For new tasks, start with existing configurations and gradually adjust parameters Version Control : Configuration files for important experiments should be version controlled to reproduce results","title":"config"},{"location":"config/#configuration-system","text":"The OpenHAIV framework uses a flexible YAML-based configuration system that allows users to easily define and modify various experimental parameters without changing the code. This document provides detailed information about the structure, usage, and major components of the configuration files.","title":"Configuration System"},{"location":"config/#configuration-file-structure","text":"OpenHAIV configuration files follow a hierarchical structure, mainly divided into the following sections: Base Configuration : Defines basic parameters for experiments, such as random seed, device, output directory, etc. Trainer Configuration : Defines parameters for the training process Model Configuration : Defines model architecture and related parameters Algorithm Configuration : Defines specific algorithms and methods Data Loader Configuration : Defines datasets and data loading parameters Optimizer Configuration : Defines optimization algorithms and related parameters Scheduler Configuration : Defines learning rate scheduling strategies Configuration files can inherit from other configuration files through the _base_ field, enabling modular and reusable configurations.","title":"Configuration File Structure"},{"location":"config/#configuration-modules-in-detail","text":"","title":"Configuration Modules in Detail"},{"location":"config/#configalgorithms","text":"Algorithm configurations define the specific algorithms and methods used in experiments, including:","title":"config.algorithms"},{"location":"config/#supervised-learning-algorithms","text":"algorithm: type: StandardSL # Standard supervised learning","title":"Supervised Learning Algorithms"},{"location":"config/#class-incremental-learning-algorithms","text":"algorithm: type: LwF # Learning without Forgetting # Algorithm-specific parameters temperature: 2.0 alpha: 1.0 Other supported class-incremental learning algorithms include: Finetune , Joint , iCaRL , EWC , BiC , WA , DER , Coil , FOSTER , SSRE , FeTrIL , MEMO , etc.","title":"Class-incremental Learning Algorithms"},{"location":"config/#few-shot-class-incremental-learning-algorithms","text":"algorithm: type: SAVC # Few-shot class-incremental learning algorithm # Algorithm-specific parameters alpha: 1.0 beta: 0.1","title":"Few-shot Class-incremental Learning Algorithms"},{"location":"config/#out-of-distribution-detection-algorithms","text":"algorithm: type: MSP # Maximum Softmax Probability # or type: MLS # Maximum Logit Score # or type: MCM # Maximum Concept Matching Other supported out-of-distribution detection algorithms include: ODIN , VIM , MDS , DML , FDBD , GODIN , MCM , GL-MCM , etc.","title":"Out-of-Distribution Detection Algorithms"},{"location":"config/#configdataloader","text":"Data loader configurations define the datasets and data loading parameters used in experiments: _base_: configs/dataloader/OES/oes.yaml # Inherit base dataset configuration dataloader: train: dataset: type: OES # Dataset type root: /path/to/dataset # Dataset path split: train # Dataset split batch_size: 128 # Batch size num_workers: 4 # Number of data loading worker threads shuffle: True # Whether to shuffle data val: # Validation set configuration dataset: type: OES root: /path/to/dataset split: val batch_size: 128 num_workers: 4 shuffle: False Supported datasets include: OES , CIFAR10 , CIFAR100 , ImageNet , ImageNetR , CUB200 , Remote , Food101 , Caltech101 , etc.","title":"config.dataloader"},{"location":"config/#configmodel","text":"Model configurations define the model architecture and related parameters used in experiments: model: type: ResNet18 # Model type # Or use a more complex definition type: ResNet_Base network: type: ResNet18 num_classes: 94 checkpoint: \"/path/to/checkpoint.pth\" # Pre-trained model path loss: CrossEntropyLoss # Loss function type Supported models include: - Standard CNN models: ResNet18 , ResNet34 , ResNet50 , ResNet101 - Vision-language models: CLIP-B/16 , CLIP-B/32 , RSCLIP-B/16 , RSCLIP-B/32 - Algorithm-specific models: AliceNET , CoOp , LoCoOp , SCT , DPM","title":"config.model"},{"location":"config/#configpipeline","text":"Pipeline configuration files integrate all of the above components into a complete experiment configuration, for example, a supervised learning pipeline configuration: _base_: configs/dataloader/OES/oes.yaml # Inherit data loader configuration trainer: type: PreTrainer # Trainer type max_epochs: 10 # Maximum training epochs algorithm: type: StandardSL # Algorithm type model: type: ResNet18 # Model type criterion: type: CrossEntropyLoss # Loss function optimizer: type: Adam # Optimizer lr: 0.0003 # Learning rate weight_decay: 0.0001 # Weight decay scheduler: type: Constant # Scheduler type seed: 0 # Random seed device: cuda # Device exp_name: exp # Experiment name work_dir: ./output/supervised/sl_oes_rn18 # Output directory","title":"config.pipeline"},{"location":"config/#how-to-use-configurations","text":"Configuration files can be passed to the training script via command line: python ncdia/train.py --cfg configs/pipeline/supervised_learning/sl_oes_rn18.yaml --opts device='cuda:0' The --opts parameter allows overriding any parameter in the configuration file.","title":"How to Use Configurations"},{"location":"config/#configuration-inheritance-mechanism","text":"OpenHAIV's configuration system supports composition based on inheritance, making configurations more modular and reusable: _base_: [ configs/dataloader/OES/oesfull.yaml, # Inherit data loader configuration configs/algorithms/ood_detection/dml.yaml, # Inherit algorithm configuration ] # Override or add specific parameters trainer: type: DetTrainer max_epochs: 10 model: type: ResNet_Base network: type: ResNet18 num_classes: 94 Through the inheritance mechanism, repetitive configurations can be avoided, improving the maintainability of configuration files.","title":"Configuration Inheritance Mechanism"},{"location":"config/#configuration-best-practices","text":"Modular Configuration : Extract common configurations as base configuration files, and combine them through inheritance Use Relative Paths : Paths in configuration files should use paths relative to the project root directory when possible Comment Key Parameters : Add comments to important parameters to improve readability Parameter Tuning : For new tasks, start with existing configurations and gradually adjust parameters Version Control : Configuration files for important experiments should be version controlled to reproduce results","title":"Configuration Best Practices"},{"location":"contributing/","text":"\ud83d\udee0\ufe0f Contributing Guidelines We welcome contributions to OpenHAIV \ud83e\udd17 \ud83d\udc47 If you're interested in improving the project, please follow these guidelines \ud83d\udc1b Reporting Issues Check existing issues first to avoid duplicates Use the issue template when available Be specific about the problem: Include steps to reproduce Provide environment details (OS, Python version, dependencies) Add screenshots if applicable Describe expected vs. actual behavior \ud83d\udca1 Submitting Pull Requests Create an issue first to discuss major changes Fork the repository and create a branch from main Follow the coding style used throughout the project: Adhere to PEP 8 guidelines Use meaningful variable/function names Add docstrings for new functions/classes Write tests for new features Ensure all tests pass before submitting Update documentation reflecting your changes Make atomic commits with clear messages","title":"Contributing"},{"location":"contributing/#contributing-guidelines","text":"We welcome contributions to OpenHAIV \ud83e\udd17 \ud83d\udc47 If you're interested in improving the project, please follow these guidelines","title":"\ud83d\udee0\ufe0f Contributing Guidelines"},{"location":"contributing/#reporting-issues","text":"Check existing issues first to avoid duplicates Use the issue template when available Be specific about the problem: Include steps to reproduce Provide environment details (OS, Python version, dependencies) Add screenshots if applicable Describe expected vs. actual behavior","title":"\ud83d\udc1b Reporting Issues"},{"location":"contributing/#submitting-pull-requests","text":"Create an issue first to discuss major changes Fork the repository and create a branch from main Follow the coding style used throughout the project: Adhere to PEP 8 guidelines Use meaningful variable/function names Add docstrings for new functions/classes Write tests for new features Ensure all tests pass before submitting Update documentation reflecting your changes Make atomic commits with clear messages","title":"\ud83d\udca1 Submitting Pull Requests"},{"location":"document/","text":"config config.algorithms config.dataloader config.model config.pipeline ncdia algorithms Includes incremental learning algorithms, new class discovery algorithms, and out-of-distribution detection algorithms, as well as supervised learning algorithms. ncd.autoncd.py Modules related to novel class discovery. AutoNCD (model, train_loader, test_loader, device=None, verbose=False) Class for novel class discovery. model train_loader test_loader device verbose ncdia.dataloader ncdia.inference ncdia.model ncdia.trainers ncdia.utils scripts","title":"Document"},{"location":"document/#config","text":"","title":"config"},{"location":"document/#configalgorithms","text":"","title":"config.algorithms"},{"location":"document/#configdataloader","text":"","title":"config.dataloader"},{"location":"document/#configmodel","text":"","title":"config.model"},{"location":"document/#configpipeline","text":"","title":"config.pipeline"},{"location":"document/#ncdia","text":"","title":"ncdia"},{"location":"document/#algorithms","text":"Includes incremental learning algorithms, new class discovery algorithms, and out-of-distribution detection algorithms, as well as supervised learning algorithms.","title":"algorithms"},{"location":"document/#ncdautoncdpy","text":"Modules related to novel class discovery.","title":"ncd.autoncd.py"},{"location":"document/#autoncd-model-train_loader-test_loader-devicenone-verbosefalse","text":"Class for novel class discovery. model train_loader test_loader device verbose","title":"AutoNCD (model, train_loader, test_loader, device=None, verbose=False)"},{"location":"document/#ncdiadataloader","text":"","title":"ncdia.dataloader"},{"location":"document/#ncdiainference","text":"","title":"ncdia.inference"},{"location":"document/#ncdiamodel","text":"","title":"ncdia.model"},{"location":"document/#ncdiatrainers","text":"","title":"ncdia.trainers"},{"location":"document/#ncdiautils","text":"","title":"ncdia.utils"},{"location":"document/#scripts","text":"","title":"scripts"},{"location":"methods/","text":"Supported Methods for OpenHAIV \ud83c\udf31 Class-Incremental Learning CNN-based methods Joint : update models using all the data from all classes. Finetune : baseline method which simply updates model using current data. LwF : Learning without Forgetting. ECCV 2016 [ paper ] EWC : Overcoming catastrophic forgetting in neural networks. PNAS 2017 [ paper ] iCaRL : Incremental Classifier and Representation Learning. CVPR 2017 [ paper ] BiC : Large Scale Incremental Learning. CVPR 2019 [ paper ] WA : Maintaining Discrimination and Fairness in Class Incremental Learning. CVPR 2020 [ paper ] DER : Dynamically Expandable Representation for Class Incremental Learning. CVPR 2021 [ paper ] Coil : Co-Transport for Class-Incremental Learning. ACM MM 2021 [ paper ] GEM : Gradient Episodic Memory for Continual Learning. NIPS 2017 [ paper ] SSRE : Self-Sustaining Representation Expansion for Non-Exemplar Class-Incremental Learning. CVPR 2022 [ paper ] FOSTER : Feature Boosting and Compression for Class-incremental Learning. ECCV 2022 [ paper ] FeTrIL : Feature Translation for Exemplar-Free Class-Incremental Learning. WACV 2023 [ paper ] MEMO : Memory-Efficient Class-Incremental Learning. ICLR 2023 [ paper ] ViT-based methods Joint : update models using all the data from all classes. Few-shot class-incremental learning Alice : Few-Shot Class-Incremental Learning from an Open-Set Perspective. ECCV 2022 [ paper ] FACT : Forward Compatible Few-Shot Class-Incremental Learning. CVPR 2022 [ paper ] SAVC : Semantic-Aware Virtual Contrastive Constraint for Few-Shot Class-Incremental Learning. CVPR 2023 [ paper ] \ud83d\udea8 Out-of-Distribution Detection CNN-based Methods MSP : A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks. ICLR 2017 [ paper ] ODIN : Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks. ICLR 2018 [ paper ] MDS : A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks. NeurIPS 2018 [ paper ] MLS : Scaling Out-of-Distribution Detection for Real-World Settings. ICML 2022 [ paper ] ViM : Out-Of-Distribution with Virtual-logit Matching. CVPR 2022 [ paper ] FDBD : Fast Decision Boundary based Out-of-Distribution Detector. ICML 2024 [ paper ] VOS : Learning What You Don't Know by Virtual Outlier Synthesis. ICLR 2022 [ paper ] LogitNorm : Mitigating Neural Network Overconfidence with Logit Normalization. ICML 2022 [ paper ] DML : Decoupling MaxLogit for Out-of-Distribution Detection. CVPR 2023 [ paper ] CLIP-based Methods MCM : Delving into Out-of-Distribution Detection with Vision-Language Representations. NeurIPS 2022 [ paper ] GLMCM : Global and Local Maximum Concept Matching for Zero-Shot Out-of-Distribution Detection. IJCV 2025 [ paper ] CoOp : Learning to Prompt for Vision-Language Models. IJCV 2022 [ paper ] LoCoOp : Few-Shot Out-of-Distribution Detection via Prompt Learning. NeurIPS 2023 [ paper ] SCT : Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection. NeurIPS 2024 [ paper ] DPM : Vision-Language Dual-Pattern Matching for Out-of-Distribution Detection. ECCV 2024 [ paper ] \ud83d\udd0d Novel Class Discovery TBD \ud83e\uddec Data Augmentation TBD","title":"Reproduced Methods"},{"location":"methods/#supported-methods-for-openhaiv","text":"","title":"Supported Methods for OpenHAIV"},{"location":"methods/#class-incremental-learning","text":"CNN-based methods Joint : update models using all the data from all classes. Finetune : baseline method which simply updates model using current data. LwF : Learning without Forgetting. ECCV 2016 [ paper ] EWC : Overcoming catastrophic forgetting in neural networks. PNAS 2017 [ paper ] iCaRL : Incremental Classifier and Representation Learning. CVPR 2017 [ paper ] BiC : Large Scale Incremental Learning. CVPR 2019 [ paper ] WA : Maintaining Discrimination and Fairness in Class Incremental Learning. CVPR 2020 [ paper ] DER : Dynamically Expandable Representation for Class Incremental Learning. CVPR 2021 [ paper ] Coil : Co-Transport for Class-Incremental Learning. ACM MM 2021 [ paper ] GEM : Gradient Episodic Memory for Continual Learning. NIPS 2017 [ paper ] SSRE : Self-Sustaining Representation Expansion for Non-Exemplar Class-Incremental Learning. CVPR 2022 [ paper ] FOSTER : Feature Boosting and Compression for Class-incremental Learning. ECCV 2022 [ paper ] FeTrIL : Feature Translation for Exemplar-Free Class-Incremental Learning. WACV 2023 [ paper ] MEMO : Memory-Efficient Class-Incremental Learning. ICLR 2023 [ paper ] ViT-based methods Joint : update models using all the data from all classes. Few-shot class-incremental learning Alice : Few-Shot Class-Incremental Learning from an Open-Set Perspective. ECCV 2022 [ paper ] FACT : Forward Compatible Few-Shot Class-Incremental Learning. CVPR 2022 [ paper ] SAVC : Semantic-Aware Virtual Contrastive Constraint for Few-Shot Class-Incremental Learning. CVPR 2023 [ paper ]","title":"\ud83c\udf31 Class-Incremental Learning"},{"location":"methods/#out-of-distribution-detection","text":"CNN-based Methods MSP : A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks. ICLR 2017 [ paper ] ODIN : Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks. ICLR 2018 [ paper ] MDS : A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks. NeurIPS 2018 [ paper ] MLS : Scaling Out-of-Distribution Detection for Real-World Settings. ICML 2022 [ paper ] ViM : Out-Of-Distribution with Virtual-logit Matching. CVPR 2022 [ paper ] FDBD : Fast Decision Boundary based Out-of-Distribution Detector. ICML 2024 [ paper ] VOS : Learning What You Don't Know by Virtual Outlier Synthesis. ICLR 2022 [ paper ] LogitNorm : Mitigating Neural Network Overconfidence with Logit Normalization. ICML 2022 [ paper ] DML : Decoupling MaxLogit for Out-of-Distribution Detection. CVPR 2023 [ paper ] CLIP-based Methods MCM : Delving into Out-of-Distribution Detection with Vision-Language Representations. NeurIPS 2022 [ paper ] GLMCM : Global and Local Maximum Concept Matching for Zero-Shot Out-of-Distribution Detection. IJCV 2025 [ paper ] CoOp : Learning to Prompt for Vision-Language Models. IJCV 2022 [ paper ] LoCoOp : Few-Shot Out-of-Distribution Detection via Prompt Learning. NeurIPS 2023 [ paper ] SCT : Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection. NeurIPS 2024 [ paper ] DPM : Vision-Language Dual-Pattern Matching for Out-of-Distribution Detection. ECCV 2024 [ paper ]","title":"\ud83d\udea8 Out-of-Distribution Detection"},{"location":"methods/#novel-class-discovery","text":"TBD","title":"\ud83d\udd0d Novel Class Discovery"},{"location":"methods/#data-augmentation","text":"TBD","title":"\ud83e\uddec Data Augmentation"},{"location":"ncdia/","text":"ncdia ncdia.algorithms Includes incremental learning algorithms, new class discovery algorithms, and out-of-distribution detection algorithms, as well as supervised learning algorithms. ncdia.algorithms.base.py BaseAlg Basic algorithm class to define the interface of an algorithm. __init__(self, trainer) The constructor method that initializes an instance of BaseAlg . Parameters: trainer ( object ): Trainer object. train_step(self, trainer, data, label, *args, kwargs)** Training step. Parameters: trainer ( object ): Trainer object. data ( torch.Tensor ): Input data. label ( torch.Tensor ): Label data. args ( tuple ): Additional arguments. kwargs ( dict ): Additional keyword arguments. Returns: results ( dict ): Training results. Contains the following keys: \"loss\" : Loss value. \"acc\" : Accuracy value. other \"key:value\" pairs. val_step(self, trainer, data, label, *args, kwargs)** Validation step. Parameters: trainer ( object ): Trainer object. data ( torch.Tensor ): Input data. label ( torch.Tensor ): Label data. args ( tuple ): Additional arguments. kwargs ( dict ): Additional keyword arguments. Returns: results ( dict ): Validation results. Contains the following keys: \"loss\" : Loss value. \"acc\" : Accuracy value. other \"key:value\" pairs. test_step(self, trainer, data, label, *args, kwargs)** Test step. Parameters: trainer ( object ): Trainer object. data ( torch.Tensor ): Input data. label ( torch.Tensor ): Label data. args ( tuple ): Additional arguments. kwargs ( dict ): Additional keyword arguments. Returns: results ( dict ): Test results. Contains the following keys: \"loss\" : Loss value. \"acc\" : Accuracy value. other \"key:value\" pairs. ncdia.algorithms.incremental Include implementation of Class Incremental Learning (CIL) and Few-shot Class Incremental Learning (FSCIL) algorithm. CIL Finetune LwF EwC iCarL IL2A WA FSCIL ALICE FACT SAVC ncdia.algorithms.ncd.autoncd.py Modules related to novel class discovery. AutoNCD Class for evaluating with OOD metrics and relabeling the OOD dataset for the next session. __init__(self, model, train_loader, test_loader, device=None, verbose=False) The constructor method that initializes an instance of AutoNCD . Parameters: model ( nn.Module ): model to be evaluated. train_loader ( DataLoader ): train dataloader. test_loader ( DataLoader ): test dataloader. device ( torch.device, optional ): device to run the evaluation. Default to None. verbose ( bool, optional ): print the progress bar. Default to False. inference(self, dataloader, split='train') Inference the model on the dataloader and return relevant information. If split is 'train', return the prototype of the training data. Parameters: dataloader ( DataLoader ): dataloader for evaluation. split ( str, optional ): train or test. Defaults to 'train'. Returns: If split is 'train': features ( torch.Tensor ): feature vectors, (N, D). logits ( torch.Tensor ): logit vectors, (N, C). prototype_cls ( torch.Tensor ): prototype vectors, (C, D). If split is 'test': imgpaths ( list ): image paths (list). features ( torch.Tensor ): feature vectors, (N, D). logits ( torch.Tensor ): logit vectors, (N, C). preds ( torch.Tensor ): prediction labels, (N,). labels ( torch.Tensor ): ground truth labels, (N,). relabel(self, ood_loader, metrics=[], tpr_th=0.95, prec_th=None) Relabel the OOD dataset for the next session. Parameters: ood_loader ( DataLoader ): OOD dataloader for relabeling. metrics ( list, optional ): metrics to evaluate the OOD dataset. Defaults to []. tpr_th ( float, optional ): True positive rate threshold. Defaults to 0.95. prec_th ( float, optional ): Precision threshold. Defaults to None. Returns: ood_loader ( DataLoader ): relabeled OOD dataloader. _split_cluster_label(self, y_label, y_pred, ood_class) Calculate clustering accuracy. Require scikit-learn installed. First compute linear assignment on all data, then look at how good the accuracy is on subsets. Parameters: y_label ( numpy.array ): true labels, (n_samples,) y_pred ( numpy.array ): predicted labels (n_samples,) ood_class : out-of-distribution class labels Returns: cluster_label : cluster label search_discrete_point(self, novel_feat, novel_target) TODO ncdia.algorithms.ood.autoood.py AutoOOD Class for evaluating OOD detection methods. eval(prototype_cls, fc_weight, train_feats, train_logits, id_feats, id_logits, id_labels, ood_feats, ood_logits, ood_labels, metrics=[], tpr_th=0.95, prec_th=None, id_attrs=None, ood_attrs=None, prototype_att=None) Evaluate the OOD detection methods and return OOD scores. Parameters: prototype_cls ( np.ndarray ): prototype of training data fc_weight ( np.ndarray ): weight of the last layer train_feats ( np.ndarray ): feature of training data train_logits ( np.ndarray ): logits of training data id_feats ( np.ndarray ): feature of ID data id_logits ( np.ndarray ): logits of ID data id_labels ( np.ndarray ): labels of ID data ood_feats ( np.ndarray ): feature of OOD data ood_logits ( np.ndarray ): logits of OOD data ood_labels ( np.ndarray ): labels of OOD data metrics ( list, optional ): list of OOD detection methods to evaluate. Defaults to []. tpr_th ( float, optional ): True positive rate threshold. Defaults to 0.95. prec_th ( float, optional ): Precision threshold. Defaults to None. Returns: ood_scores ( dict ): OOD scores, keys are the names of the OOD detection methods, values are the OOD scores and search threshold. Each value is a tuple containing the following: ood metrics ( tuple ): fpr ( float ): false positive rate auroc ( float ): area under the ROC curve aupr_in ( float ): area under the precision-recall curve for in-distribution samples aupr_out ( float ): area under the precision-recall curve for out-of-distribution samples search threshold ( tuple ): threshold for OOD detection if prec_th is not None best_th ( float ): best threshold for OOD detection conf ( torch.Tensor ): confidence scores label ( torch.Tensor ): label array precisions ( float ): precision when precisions >= prec_th recalls ( float ): recall when precisions >= prec_th inference(metrics, logits, feat, train_logits, train_feat, fc_weight, prototype, logits_att=None, prototype_att=None) Inferencec method for OOD detection Parameters: metrics ( list ): the ood metrics used for inference. logits ( np.ndarray ): logits of inference data. feat ( np.ndarray ): features of inference data. train_logits ( np.ndarray ): logits of training data. train_feat ( np.ndarray ): features of training data. fc_weight ( np.ndarray ): weight of the last layer. prototype ( np.ndarray ): prototypes of training data. logits_att ( np.ndarray, optional ): logits of attribute. prototype_att ( np.ndarray, optional ): prototypes of attribute. Returns: conf ( dict ): contains the confidence using different metrics, conf[metric] ( torch.Tensor ) is the confidence using specific metric. ncdia.algorithms.ood.methods.py msp(id_gt, id_logits, ood_gt, ood_logits, tpr_th=0.95, prec_th=None) Maximum Softmax Probability (MSP) method for OOD detection. A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks. Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_logits ( torch.Tensor ): ID logits. Shape (N, C). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_logits ( torch.Tensor ): OOD logits. Shape (M, C). tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching - threshold. If None, not searching for threshold. Default is None. Returns: conf ( np.ndarray ): Confidence scores. Shape (N + M,). label ( np.ndarray ): Label array. Shape (N + M,). fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution best_th ( float ): Threshold for OOD detection. If prec_th is None, None. prec ( float ): Precision at the threshold. If prec_th is None, None. recall ( float ): Recall at the threshold. If prec_th is None, None. mcm(id_gt, id_logits, ood_gt, ood_logits, T=2, tpr_th=0.95, prec_th=None) Maximum Concept Matching (MCM) method for OOD detection. Delving into Out-of-Distribution Detection with Vision-Language Representations Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_logits ( torch.Tensor ): ID logits. Shape (N, C). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_logits ( torch.Tensor ): OOD logits. Shape (M, C). T ( int ): Temperature for softmax. tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is None. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution. max_logit(id_gt, id_logits, ood_gt, ood_logits, tpr_th=0.95, prec_th=None) Maximum Logit (MaxLogit) method for OOD detection. Scaling Out-of-Distribution Detection for Real-World Settings Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_logits ( torch.Tensor ): ID logits. Shape (N, C). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_logits ( torch.Tensor ): OOD logits. Shape (M, C). tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is None. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution energy(id_gt, id_logits, ood_gt, ood_logits, tpr_th=0.95, prec_th=None) Energy-based method for OOD detection. Energy-based Out-of-distribution Detection Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_logits ( torch.Tensor ): ID logits. Shape (N, C). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_logits ( torch.Tensor ): OOD logits. Shape (M, C). tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is None. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution vim(id_gt, id_logits, id_feat, ood_gt, ood_logits, ood_feat, train_logits, train_feat, tpr_th=0.95, prec_th=None) Virtual-Logit Matching (ViM) method for OOD detection. ViM: Out-of-Distribution With Virtual-Logit Matching Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_logits ( torch.Tensor ): ID logits. Shape (N, C). id_feat ( torch.Tensor ): ID features. Shape (N, D). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_logits ( torch.Tensor ): OOD logits. Shape (M, C). ood_feat ( torch.Tensor ): OOD features. Shape (M, D). train_logits ( torch.Tensor ): Training logits. Shape (K, C). train_feat ( torch.Tensor ): Training features. Shape (K, D). tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is None. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution dml(id_gt, id_feat, ood_gt, ood_feat, fc_weight, tpr_th=0.95, prec_th=None) Decoupled MaxLogit (DML) method for OOD detection. Decoupling MaxLogit for Out-of-Distribution Detection Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_feat ( torch.Tensor ): ID features. Shape (N, D). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_feat ( torch.Tensor ): OOD features. Shape (M, D). fc_weight ( torch.Tensor ): FC layer weight. Shape (C, D). tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is None. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution dmlp(id_gt, id_logits, id_feat, ood_gt, ood_logits, ood_feat, fc_weight, prototype,tpr_th=0.95, prec_th=None) Decoupled MaxLogit+ (DML+) method for OOD detection. Decoupling MaxLogit for Out-of-Distribution Detection Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_logits ( torch.Tensor ): ID logits. Shape (N, C). id_feat ( torch.Tensor ): ID features. Shape (N, D). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_logits ( torch.Tensor ): OOD logits. Shape (M, C). ood_feat ( torch.Tensor ): OOD features. Shape (M, D). fc_weight ( torch.Tensor ): FC layer weight. Shape (D, C). prototype ( torch.Tensor ): Prototype. Shape (D, C). tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is None. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution prot(id_gt, id_logits, ood_gt, ood_logits, prototypes: list, tpr_th=0.95, prec_th=None) Prototype-based (Prot) method for OOD detection. Parameters: id_gt ( torch.Tensor ): ID ground truth labels, shape (N,). id_logits ( list of torch.Tensor ): ID logits, containing shape (N, C). ood_gt ( torch.Tensor ): OOD ground truth labels, shape (M,). ood_logits ( list of torch.Tensor ): OOD logits, containing shape (M, C). prototypes ( list of torch.Tensor ): Prototypes, containing shape (D, C). tpr_th ( float ): True positive rate threshold to compute false positive rate. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution ncdia.algorithms.ood.inference.py The inference version of implemented ood methods in ncdia.algorithms.ood.methods.py ncdia.algorithms.ood.metrics.py ood_metrics(conf, label, tpr_th=0.95) Compute OOD metrics. Parameters: conf ( np.ndarray ): Confidence scores. Shape (N,). label ( np.ndarray ): Label array. Shape (N,). Containing: -1: OOD samples. int >= 0: ID samples with class labels tpr_th ( float ): True positive rate threshold to compute false positive rate. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution samples. search_threshold(conf, label, prec_th) Search for the threshold for OOD detection. Parameters: conf ( np.ndarray ): Confidence scores. Shape (N,). label ( np.ndarray ): Label array. Shape (N,). Containing: -1: OOD samples. int >= 0: ID samples with class labels prec_th ( float ): Precision threshold. Returns: best_th ( float ): Threshold for OOD detection. prec ( float ): Precision at the threshold. recall ( float ): Recall at the threshold. ncdia.algorithms.supervised.standard.py Modules related to supervised learning StandardSL Class inherits from BaseAlg . Standard supervised learning algorithm train_step(self, trainer, data, label, *args, **kwargs) Training step for standard supervised learning. Parameters: trainer ( object ): Trainer object. data ( torch.Tensor ): Input data. label ( torch.Tensor ): Label data. args ( tuple ): Additional arguments. kwargs ( dict ): Additional keyword arguments. Returns: results ( dict ): Training results. Contains the following keys: \"loss\" : Loss value. \"acc\" : Accuracy value. val_step(self, trainer, data, label, *args, **kwargs) Validation step for standard supervised learning. Parameters: trainer ( object ): Trainer object. data ( torch.Tensor ): Input data. label ( torch.Tensor ): Label data. args ( tuple ): Additional arguments. kwargs ( dict ): Additional keyword arguments. Returns: results ( dict ): Validation results. Contains the following: \"loss\" : Loss value. \"acc\" : Accuracy value. test_step(self, trainer, data, label, *args, **kwargs) Test step for standard supervised learning. Parameters: trainer (object): Trainer object. data (torch.Tensor): Input data. label (torch.Tensor): Label data. args (tuple): Additional arguments. kwargs (dict): Additional keyword arguments. Returns: results ( dict ): Test results. Contains the following: \"loss\" : Loss value. \"acc\" : Accuracy value. ncdia.dataloader ncdia.dataloader.base.py build_dataloader(kwargs) Build data loader. Parameters: kwargs ( dict ): Arguments for DataLoader. Contains the following: dataset ( dict ): Dataset configuration. other arguments for DataLoader, such as batch_size , shuffle , etc. Returns: loader ( DataLoader ): Data loader. ncdia.dataloader.tools.py Implements some of the commonly used dataloaders ncdia.dataloader.datasets Implements some of the commonly used datasets, including: CIFAR100 CUB200 Caltech101 Food101 ImageNet ImageNetR BM200 ncdia.dataloader.augmentations Implements some of the commonly used augmentation methods. ncdia.model ncdia.models.models.py get_network(config) load model. Parameters: - trainer ( config ): model config ncdia.models.net.inc_net.py BaseNet BaseNet for incremental learning. __init__(self, network, base_classes, num_classes, att_classes, net_alice, mode) The constructor method that initializes an instance of BaseNet . Parameters: network ( config ): The config of the network. base_classes ( int ): The number of base classes. num_classes ( int ): The total class number. att_classes ( int ): The attribute class number. mode ( str ): classifier mode. feature_dim(self) The feature dimension of the network. Returns: out_dim ( int ) feature dimension of the network. extractor_vector(self, x) get features of input x. Parameters: x ( tensor ): input data. Returns: out_features ( tensor ) features of the input. forward(self, x) forworad pass of the network. Parameters: x ( tensor ): input data. Returns: results ( dict ): forward pass results. Contains the following keys: \"fmaps\" : [x_1, x_2, ..., x_n], \"features\" : features \"logits\" : logits copy(self) copy. Returns: copy function . freeze(self) freeze parameters. IncrementalNet Incremental Network which follows BaseNet. __init__(self, network, base_classes, num_classes, att_classes, net_alice, mode) The constructor method that initializes an instance of BaseNet . Parameters: network ( config ): The config of the network. base_classes ( int ): The number of base classes. num_classes ( int ): The total class number. att_classes ( int ): The attribute class number. mode ( str ): classifier mode. update_fc(self, nb_classes) update fc parameter, generate new fc and copy old parameter. Parameters: network ( int ): New class number. Returns: fc : updated fc layers. generate_fc(self, in_dim, out_dim) Parameters: in_dim ( int ): new fc in dimension. out_dim ( int ): new fc out dimension. Returns: fc : new fc layers. forward(self, x) forworad pass of the network. Parameters: x ( tensor ): input data. Returns: results ( dict ): forward pass results. Contains the following keys: \"fmaps\" : [x_1, x_2, ..., x_n], \"features\" : features \"logits\" : logits weight_align(self, increment) normalize classifer parameters. Parameters: increment ( int ): incremental classes. ncdia.trainers ncdia.trainers.base.py BaseTrainer Basic trainer class for training models. Attributes: model ( nn.Module ): Neural network models. train_loader ( DataLoader ): DataLoader for training. val_loader ( DataLoader ): DataLoader for validation. test_loader ( DataLoader ): DataLoader for testing. optimizer ( Optimizer ): Optimizer. scheduler ( lr_scheduler._LRScheduler ): Learning rate scheduler. criterion ( Callable ): Criterion for training. algorithm ( object ): Algorithm for training. metrics ( dict ): Metrics for evaluation and testing. session ( int ): Session number. max_epochs ( int ): Total epochs for training. max_train_iters ( int ): Iterations on one epoch for training. max_val_iters ( int ): Iterations on one epoch for validation. max_test_iters ( int ): Iterations on one epoch for testing. epoch ( int ): Current training epoch. iter ( int ): Current iteration or index of the current batch. cfg ( Configs ): Configuration for trainer. hooks ( List[Hook] ): List of registered hooks. logger ( Logger ): Logger for logging information. device ( torch.device ): Device to use. work_dir ( str ): Working directory to save logs and checkpoints. exp_name ( str ): Experiment name. load_from ( str ): Checkpoint file path to load. Methods: __init__(self, cfg, session, model, train_loader, val_loader, test_loader, default_hooks, custom_hooks, load_from, exp_name, work_dir) The constructor method that initializes an instance of BaseTrainer . Parameters: cfg ( dict, optional ): Configuration for trainer, Contains: 'trainer' ( dict ): 'type' ( str ): Type of trainer. 'algorithm' ( dict ): 'type' ( str ): Type of algorithm. 'criterion' ( dict ): 'type' ( str ): Type of criterion for training. 'optimizer' : 'type' ( str ): Name of optimizer. 'param_groups' ( dict | None ): If provided, directly optimize param_groups and abandon model. kwargs ( dict ) for optimizer, such as 'lr', 'weight_decay', etc. 'scheduler' : 'type' ( str ): Name of scheduler. kwargs ( dict ) for scheduler, such as 'step_size', 'gamma', etc. 'device' ( str | torch.device | None ): Device to use. If None, use 'cuda' if available. 'trainloader' : 'dataset': 'type' ( str ): Type of dataset. kwargs ( dict ) for dataset, such as 'root', 'split', etc. kwargs ( dict ) for DataLoader, such as 'batch_size', 'shuffle', etc. 'valloader' : 'dataset': 'type' ( str ): Type of dataset. kwargs ( dict ) for dataset, such as 'root', 'split', etc. kwargs ( dict ) for DataLoader, such as 'batch_size', 'shuffle', etc. 'testloader' : 'dataset': 'type' ( str ): Type of dataset. kwargs ( dict ) for dataset, such as 'root', 'split', etc. kwargs ( dict ) for DataLoader, such as 'batch_size', 'shuffle', etc. 'exp_name' ( str ): Experiment name. 'work_dir' ( str ): Working directory to save logs and checkpoints. session ( int ): Session number. If == 0, execute pre-training. If > 0, execute incremental training. model ( nn.Module ): Model to be trained. train_loader ( DataLoader | dict, optional ): DataLoader for training. val_loader ( DataLoader | dict, optional ): DataLoader for validation. test_loader ( DataLoader | dict, optional ): DataLoader for testing. default_hooks ( dict, optional ): Default hooks to be registered. custom_hooks ( list, optional ): Custom hooks to be registered. load_from ( str, optional ): Checkpoint file path to load. work_dir ( str, optional ): Working directory to save logs and checkpoints. train_step(self, batch, **kwargs) Training step. This method should be implemented in subclasses. Parameters: batch ( dict | tuple | list ): A batch of data from the data loader. Returns: results (dict): Contains the following: {\"key1\": value1, \"key2\": value2,...} keys denote the description of the value, such as \"loss\" , \"acc\" , \"ccr\" , etc. values are the corresponding values of the keys, can be int , float , str , etc. val_step(self, batch, kwargs)** Validation step. This method should be implemented in subclasses. Parameters: batch ( dict | tuple | list ): A batch of data from the data loader. Returns: results (dict): Contains the following: {\"key1\": value1, \"key2\": value2,...} keys denote the description of the value, such as \"loss\" , \"acc\" , \"ccr\" , etc. values are the corresponding values of the keys, can be int , float , str , etc. test_step(self, batch, kwargs)** Test step. This method should be implemented in subclasses. Parameters: batch ( dict | tuple | list ): A batch of data from the data loader. Returns: results (dict): Contains the following: {\"key1\": value1, \"key2\": value2,...} keys denote the description of the value, such as \"loss\" , \"acc\" , \"ccr\" , etc. values are the corresponding values of the keys, can be int , float , str , etc. train(self) Launch the training process. Returns: model ( nn.Module ): Trained model. val(self) Validation process. test(self) Test process. load_ckpt(self, fpath, device='cpu') Load checkpoint from file. Parameters: fpath ( str ): Checkpoint file path. device ( str ): Device to load checkpoint. Defaults to 'cpu'. Returns: model ( nn.Module ): Loaded model. save_ckpt(self, fpath) Save checkpoint to file. Parameters: fpath ( str ): Checkpoint file path. call_hook(self, fn_name: str, kwargs)** Call all hooks with the specified function name. Parameters: fn_name ( str ): Function name to be called, such as: 'before_train_epoch' 'after_train_epoch' 'before_train_iter' 'after_train_iter' 'before_val_epoch' 'after_val_epoch' 'before_val_iter' 'after_val_iter' kwargs ( dict ): Arguments for the function. register_hook(self, hook, priority=None) Register a hook into the hook list. The hook will be inserted into a priority queue, with the specified priority (See :class: Priority for details of priorities). For hooks with the same priority, they will be triggered in the same order as they are registered. Priority of hook will be decided with the following priority: priority argument. If priority is given, it will be priority of hook. If hook argument is a dict and priority in it, the priority will be the value of hook['priority'] . If hook argument is a dict but priority not in it or hook is an instance of hook , the priority will be hook.priority . Parameters: hook ( :obj: Hook or dict ): The hook to be registered. priority (int or str or :obj: Priority , optional): Hook priority. Lower value means higher priority. register_default_hooks(self, hooks=None) Register default hooks into hook list. hooks will be registered into runner to execute some default actions like updating model parameters or saving checkpoints. Default hooks and their priorities: Hooks Priority RuntimeInfoHook VERY_HIGH (10) IterTimerHook NORMAL (50) DistSamplerSeedHook NORMAL (50) LoggerHook BELOW_NORMAL (60) ParamSchedulerHook LOW (70) CheckpointHook VERY_LOW (90) If hooks is None, above hooks will be registered by default: default_hooks = dict( logger=dict(type='LoggerHook'), model=dict(type='ModelHook'), alg=dict(type='AlgHook'), optimizer = dict(type='OptimizerHook'), scheduler = dict(type='SchedulerHook'), metric = dict(type='MetricHook'), ) If not None, hooks will be merged into default_hooks . If there are None value in default_hooks, the corresponding item will be popped from default_hooks : hooks = dict(timer=None) The final registered default hooks will be :obj: RuntimeInfoHook , :obj: DistSamplerSeedHook , :obj: LoggerHook , :obj: ParamSchedulerHook and :obj: CheckpointHook . Parameters: hooks ( dict[str, Hook or dict] ): Default hooks or configs to be registered. register_custom_hooks(self, hooks) Register custom hooks into hook list. Parameters: hooks ( list[Hook | dict] ): List of hooks or configs to be registered. register_hooks(self, default_hooks=None, custom_hooks=None) Register default hooks and custom hooks into hook list. Parameters: default_hooks ( dict[str, dict] or dict[str, Hook] ): Hooks to execute default actions like updating model parameters and saving checkpoints. Defaults to None. custom_hooks ( list[dict] or list[Hook] ): Hooks to execute custom actions like visualizing images processed by pipeline. Defaults to None. get_hooks_info(self) Get registered hooks information. Returns: info ( str ): Information of registered hooks. ncdia.trainers.pretrainer.py PreTrainer PreTrainer class for pre-training a model on session 0. Attributes: max_epochs ( int ): Total epochs for training. Methods: __init__(self, max_epochs=1, **kwargs): The constructor method that initializes an instance of PreTrainer . max_epochs ( int ): Total epochs for training. train_step(self, batch, **kwargs): Training step. val_step(self, batch, **kwargs): Validation step. test_step(self, batch, **kwargs): Test step. batch_parser(batch) Parse a batch of data. Parameters: batch ( dict | tuple | list ): A batch of data. Returns: data ( torch.Tensor | list ): Input data. label ( torch.Tensor | list ): Label data. attribute ( torch.Tensor | list ): Attribute data. imgpath ( list of str ): Image path. ncdia.trainers.inctrainer.py IncTrainer IncTrainer class for incremental training. Attributes: sess_cfg ( Configs ): Session configuration. num_sess ( int ): Number of sessions. session ( int ): Session number. If == 0, execute pre-training. If > 0, execute incremental training. hist_trainset ( MergedDataset ): Historical training dataset. hist_valset ( MergedDataset ): Historical validation dataset. hist_testset ( MergedDataset ): Historical testing dataset. Methods: __init__(self, cfg=None, sess_cfg=None, ncd_cfg=None, session=0, model=None, hist_trainset=None, hist_testset=None, old_model=None, **kwargs) The constructor method that initializes an instance of IncTrainer . Parameters: model ( nn.Module ): Model to be trained. cfg ( dict ): Configuration for trainer. sess_cfg ( Configs ): Session configuration. session ( int ): Session number. Default: 0. train(self) Incremental training. self.num_sess determines the number of sessions, and session number is stored in self.session . Returns: model ( nn.Module ): Trained model. ncdia.trainers.hooks Implements some of the commonly used hooks. Hook ncdia.trainers.hooks.hook.py Base hook class. All hooks should inherit from this class. AlgHook ncdia.trainers.hooks.alghook.py A hook to modify algorithm state in the pipeline. This class is a base class for all algorithm hooks. LoggerHook ncdia.trainers.hooks.loggerhook.py A hook to log information during training and evaluation. MetricHook ncdia.trainers.hooks.metrichook.py A hook to calculate metrics during evaluation and testing. ModelHook ncdia.trainers.hooks.modelhook.py A hook to change model state in the pipeline, such as setting device, changing model to eval mode, etc. NCDHook ncdia.trainers.hooks.ncdhook.py A hook to execute OOD and NCD detection to relabel data OptimizerHook ncdia.trainers.hooks.optimizerhook.py A hook to put optimizer to zero_grad and step during training. SchedulerHook ncdia.trainers.hooks.schedulerhook.py A hook to change learning rate during training. ncdia.trainers.optims ncdia.trainers.optims.optimizer.py build_optimizer(type, model, param_groups=None, **kwargs) Build optimizer. Parameters: type ( str ): type of optimizer model ( nn.Module | dict ): model or param_groups param_groups ( dict | None ): if provided, directly optimize param_groups and abandon model kwargs ( dict ): arguments for optimizer Returns: optimizer ( torch.optim.Optimizer ): optimizer ncdia.trainers.optims.scheduler.py Implements some of the commonly used scheduler. CosineWarmupLR LinearWarmupLR ConstantLR Methods: build_scheduler(type, optimizer, **kwargs) Build learning rate scheduler. Parameters: type ( str ): type of scheduler optimizer (t orch.optim.Optimizer ): optimizer kwargs ( dict ): arguments for scheduler Returns: lr_scheduler ( torch.optim.lr_scheduler._LRScheduler ): learning rate scheduler ncdia.trainers.priority Hook priority levels. Priority Level Value HIGHEST 0 VERY_HIGH 10 HIGH 30 ABOVE_NORMAL 40 NORMAL 50 BELOW_NORMAL 60 LOW 70 VERY_LOW 90 LOWEST 100 ncdia.utils ncdia.utils.metrics ncdia.utils.metrics.accuracy.py accuracy(output, target, topk=(1,)) Computes the accuracy over the k-top predictions for the specified values of k. Parameters: output ( torch.Tensor ): model output, shape (batch_size, num_classes) target ( torch.Tensor ): target labels, shape (batch_size) topk ( tuple ): top-k values, default is (1,) Returns: acc ( list ): accuracy values for each k in topk per_class_accuracy(output, target, topk=(1, )) Compute per class accuracy over the k-top predictions for the specified values of k Parameters: output ( torch.Tensor ): model output, shape (batch_size, num_classes) target ( torch.Tensor ): target labels, shape (batch_size) topk ( tuple ): top-k values, default is (1,) Returns: acc ( list ): accuracy values for each k in topk ncdia.utils.metrics.meter.py AverageMeter Computes and stores the average and current value. ncdia.utils.losses CrossEntropyLoss In crossentropy.py . CrossEntropyLoss with label smoothing. AngularPenaltySMLoss In angular.py . Angular Penalty Softmax Loss. Three 'loss_types' available: ['arcface', 'sphereface', 'cosface'] ncdia.utils.cfg.py Configs Include implementation of setup and use of configs. ncdia.utils.logger.py Include implementation of loggers to write output to console and external text file. ncdia.utils.registry.py Registry A registry to map strings to classes or functions. Examples: >>> REGISTRY = Registry() >>> @REGISTRY >>> def foo(): >>> return 'foo' >>> @REGISTRY.register >>> def bar(): >>> return 'bar' >>> print(REGISTRY['foo']()) foo >>> print(REGISTRY['bar']()) bar >>> print(REGISTRY) {'foo': <function foo at 0x7f9b1c0e0d30>, 'bar': <function bar at 0x7f9b1c0e0e18>} >>> print(REGISTRY['foo']) <function foo at 0x7f9b1c0e0d30> >>> print(REGISTRY['bar']) <function bar at 0x7f9b1c0e0e18> >>> print('foo' in REGISTRY) True >>> print('bar' in REGISTRY) True >>> print('foobar' in REGISTRY) False >>> print(REGISTRY.keys()) dict_keys(['foo', 'bar']) >>> print(REGISTRY.values()) dict_values([<function foo at 0x7f9b1c0e0d30>, <function bar at 0x7f9b1c0e0e18>]) >>> print(REGISTRY.items()) dict_items([('foo', <function foo at 0x7f9b1c0e0d30>), ('bar', <function bar at 0x7f9b1c0e0e18>)]) >>> print(len(REGISTRY)) 2 register_callable(self, target: callable) Register a target. Parameters: target ( callable ): callable target to be registered. register_dict(self, target) Register a dict. Parameters: target ( dict ): A dict to be registered. All its values should be callable. register(self, target) Register a target. Parameters: target ( callable | dict ): target to be registered. Returns: target ( object ): Registered target. build(self, target: dict | Configs, **kwargs) Build a target with configs. Parameters: target ( dict | Configs ): A dict to be built. It should have a key 'type' to specify the target type. It may have other keys to specify the target configs. kwargs ( dict ): Additional keyword arguments. Returns: target ( object ): A built target. ncdia.utils.tools.py mkdir_if_missing(dirname) Create dirname if it is missing. Parameters: dirname ( str ): directory path auto_device(device) Automatically set the device for the input tensor. Parameters: device ( str | torch.device | None ): device name or device object. If None, return torch.device('cuda') if available, otherwise return torch.device('cpu'). set_random_seed(seed) Set random seed for reproducibility. Parameters: seed ( int ): random seed","title":"ncdia"},{"location":"ncdia/#ncdia","text":"","title":"ncdia"},{"location":"ncdia/#ncdiaalgorithms","text":"Includes incremental learning algorithms, new class discovery algorithms, and out-of-distribution detection algorithms, as well as supervised learning algorithms.","title":"ncdia.algorithms"},{"location":"ncdia/#ncdiaalgorithmsbasepy","text":"","title":"ncdia.algorithms.base.py"},{"location":"ncdia/#basealg","text":"Basic algorithm class to define the interface of an algorithm. __init__(self, trainer) The constructor method that initializes an instance of BaseAlg . Parameters: trainer ( object ): Trainer object. train_step(self, trainer, data, label, *args, kwargs)** Training step. Parameters: trainer ( object ): Trainer object. data ( torch.Tensor ): Input data. label ( torch.Tensor ): Label data. args ( tuple ): Additional arguments. kwargs ( dict ): Additional keyword arguments. Returns: results ( dict ): Training results. Contains the following keys: \"loss\" : Loss value. \"acc\" : Accuracy value. other \"key:value\" pairs. val_step(self, trainer, data, label, *args, kwargs)** Validation step. Parameters: trainer ( object ): Trainer object. data ( torch.Tensor ): Input data. label ( torch.Tensor ): Label data. args ( tuple ): Additional arguments. kwargs ( dict ): Additional keyword arguments. Returns: results ( dict ): Validation results. Contains the following keys: \"loss\" : Loss value. \"acc\" : Accuracy value. other \"key:value\" pairs. test_step(self, trainer, data, label, *args, kwargs)** Test step. Parameters: trainer ( object ): Trainer object. data ( torch.Tensor ): Input data. label ( torch.Tensor ): Label data. args ( tuple ): Additional arguments. kwargs ( dict ): Additional keyword arguments. Returns: results ( dict ): Test results. Contains the following keys: \"loss\" : Loss value. \"acc\" : Accuracy value. other \"key:value\" pairs.","title":"BaseAlg"},{"location":"ncdia/#ncdiaalgorithmsincremental","text":"Include implementation of Class Incremental Learning (CIL) and Few-shot Class Incremental Learning (FSCIL) algorithm. CIL Finetune LwF EwC iCarL IL2A WA FSCIL ALICE FACT SAVC","title":"ncdia.algorithms.incremental"},{"location":"ncdia/#ncdiaalgorithmsncdautoncdpy","text":"Modules related to novel class discovery.","title":"ncdia.algorithms.ncd.autoncd.py"},{"location":"ncdia/#autoncd","text":"Class for evaluating with OOD metrics and relabeling the OOD dataset for the next session. __init__(self, model, train_loader, test_loader, device=None, verbose=False) The constructor method that initializes an instance of AutoNCD . Parameters: model ( nn.Module ): model to be evaluated. train_loader ( DataLoader ): train dataloader. test_loader ( DataLoader ): test dataloader. device ( torch.device, optional ): device to run the evaluation. Default to None. verbose ( bool, optional ): print the progress bar. Default to False. inference(self, dataloader, split='train') Inference the model on the dataloader and return relevant information. If split is 'train', return the prototype of the training data. Parameters: dataloader ( DataLoader ): dataloader for evaluation. split ( str, optional ): train or test. Defaults to 'train'. Returns: If split is 'train': features ( torch.Tensor ): feature vectors, (N, D). logits ( torch.Tensor ): logit vectors, (N, C). prototype_cls ( torch.Tensor ): prototype vectors, (C, D). If split is 'test': imgpaths ( list ): image paths (list). features ( torch.Tensor ): feature vectors, (N, D). logits ( torch.Tensor ): logit vectors, (N, C). preds ( torch.Tensor ): prediction labels, (N,). labels ( torch.Tensor ): ground truth labels, (N,). relabel(self, ood_loader, metrics=[], tpr_th=0.95, prec_th=None) Relabel the OOD dataset for the next session. Parameters: ood_loader ( DataLoader ): OOD dataloader for relabeling. metrics ( list, optional ): metrics to evaluate the OOD dataset. Defaults to []. tpr_th ( float, optional ): True positive rate threshold. Defaults to 0.95. prec_th ( float, optional ): Precision threshold. Defaults to None. Returns: ood_loader ( DataLoader ): relabeled OOD dataloader. _split_cluster_label(self, y_label, y_pred, ood_class) Calculate clustering accuracy. Require scikit-learn installed. First compute linear assignment on all data, then look at how good the accuracy is on subsets. Parameters: y_label ( numpy.array ): true labels, (n_samples,) y_pred ( numpy.array ): predicted labels (n_samples,) ood_class : out-of-distribution class labels Returns: cluster_label : cluster label search_discrete_point(self, novel_feat, novel_target) TODO","title":"AutoNCD"},{"location":"ncdia/#ncdiaalgorithmsoodautooodpy","text":"","title":"ncdia.algorithms.ood.autoood.py"},{"location":"ncdia/#autoood","text":"Class for evaluating OOD detection methods. eval(prototype_cls, fc_weight, train_feats, train_logits, id_feats, id_logits, id_labels, ood_feats, ood_logits, ood_labels, metrics=[], tpr_th=0.95, prec_th=None, id_attrs=None, ood_attrs=None, prototype_att=None) Evaluate the OOD detection methods and return OOD scores. Parameters: prototype_cls ( np.ndarray ): prototype of training data fc_weight ( np.ndarray ): weight of the last layer train_feats ( np.ndarray ): feature of training data train_logits ( np.ndarray ): logits of training data id_feats ( np.ndarray ): feature of ID data id_logits ( np.ndarray ): logits of ID data id_labels ( np.ndarray ): labels of ID data ood_feats ( np.ndarray ): feature of OOD data ood_logits ( np.ndarray ): logits of OOD data ood_labels ( np.ndarray ): labels of OOD data metrics ( list, optional ): list of OOD detection methods to evaluate. Defaults to []. tpr_th ( float, optional ): True positive rate threshold. Defaults to 0.95. prec_th ( float, optional ): Precision threshold. Defaults to None. Returns: ood_scores ( dict ): OOD scores, keys are the names of the OOD detection methods, values are the OOD scores and search threshold. Each value is a tuple containing the following: ood metrics ( tuple ): fpr ( float ): false positive rate auroc ( float ): area under the ROC curve aupr_in ( float ): area under the precision-recall curve for in-distribution samples aupr_out ( float ): area under the precision-recall curve for out-of-distribution samples search threshold ( tuple ): threshold for OOD detection if prec_th is not None best_th ( float ): best threshold for OOD detection conf ( torch.Tensor ): confidence scores label ( torch.Tensor ): label array precisions ( float ): precision when precisions >= prec_th recalls ( float ): recall when precisions >= prec_th inference(metrics, logits, feat, train_logits, train_feat, fc_weight, prototype, logits_att=None, prototype_att=None) Inferencec method for OOD detection Parameters: metrics ( list ): the ood metrics used for inference. logits ( np.ndarray ): logits of inference data. feat ( np.ndarray ): features of inference data. train_logits ( np.ndarray ): logits of training data. train_feat ( np.ndarray ): features of training data. fc_weight ( np.ndarray ): weight of the last layer. prototype ( np.ndarray ): prototypes of training data. logits_att ( np.ndarray, optional ): logits of attribute. prototype_att ( np.ndarray, optional ): prototypes of attribute. Returns: conf ( dict ): contains the confidence using different metrics, conf[metric] ( torch.Tensor ) is the confidence using specific metric.","title":"AutoOOD"},{"location":"ncdia/#ncdiaalgorithmsoodmethodspy","text":"msp(id_gt, id_logits, ood_gt, ood_logits, tpr_th=0.95, prec_th=None) Maximum Softmax Probability (MSP) method for OOD detection. A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks. Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_logits ( torch.Tensor ): ID logits. Shape (N, C). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_logits ( torch.Tensor ): OOD logits. Shape (M, C). tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching - threshold. If None, not searching for threshold. Default is None. Returns: conf ( np.ndarray ): Confidence scores. Shape (N + M,). label ( np.ndarray ): Label array. Shape (N + M,). fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution best_th ( float ): Threshold for OOD detection. If prec_th is None, None. prec ( float ): Precision at the threshold. If prec_th is None, None. recall ( float ): Recall at the threshold. If prec_th is None, None. mcm(id_gt, id_logits, ood_gt, ood_logits, T=2, tpr_th=0.95, prec_th=None) Maximum Concept Matching (MCM) method for OOD detection. Delving into Out-of-Distribution Detection with Vision-Language Representations Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_logits ( torch.Tensor ): ID logits. Shape (N, C). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_logits ( torch.Tensor ): OOD logits. Shape (M, C). T ( int ): Temperature for softmax. tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is None. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution. max_logit(id_gt, id_logits, ood_gt, ood_logits, tpr_th=0.95, prec_th=None) Maximum Logit (MaxLogit) method for OOD detection. Scaling Out-of-Distribution Detection for Real-World Settings Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_logits ( torch.Tensor ): ID logits. Shape (N, C). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_logits ( torch.Tensor ): OOD logits. Shape (M, C). tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is None. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution energy(id_gt, id_logits, ood_gt, ood_logits, tpr_th=0.95, prec_th=None) Energy-based method for OOD detection. Energy-based Out-of-distribution Detection Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_logits ( torch.Tensor ): ID logits. Shape (N, C). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_logits ( torch.Tensor ): OOD logits. Shape (M, C). tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is None. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution vim(id_gt, id_logits, id_feat, ood_gt, ood_logits, ood_feat, train_logits, train_feat, tpr_th=0.95, prec_th=None) Virtual-Logit Matching (ViM) method for OOD detection. ViM: Out-of-Distribution With Virtual-Logit Matching Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_logits ( torch.Tensor ): ID logits. Shape (N, C). id_feat ( torch.Tensor ): ID features. Shape (N, D). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_logits ( torch.Tensor ): OOD logits. Shape (M, C). ood_feat ( torch.Tensor ): OOD features. Shape (M, D). train_logits ( torch.Tensor ): Training logits. Shape (K, C). train_feat ( torch.Tensor ): Training features. Shape (K, D). tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is None. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution dml(id_gt, id_feat, ood_gt, ood_feat, fc_weight, tpr_th=0.95, prec_th=None) Decoupled MaxLogit (DML) method for OOD detection. Decoupling MaxLogit for Out-of-Distribution Detection Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_feat ( torch.Tensor ): ID features. Shape (N, D). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_feat ( torch.Tensor ): OOD features. Shape (M, D). fc_weight ( torch.Tensor ): FC layer weight. Shape (C, D). tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is None. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution dmlp(id_gt, id_logits, id_feat, ood_gt, ood_logits, ood_feat, fc_weight, prototype,tpr_th=0.95, prec_th=None) Decoupled MaxLogit+ (DML+) method for OOD detection. Decoupling MaxLogit for Out-of-Distribution Detection Parameters: id_gt ( torch.Tensor ): ID ground truth labels. Shape (N,). id_logits ( torch.Tensor ): ID logits. Shape (N, C). id_feat ( torch.Tensor ): ID features. Shape (N, D). ood_gt ( torch.Tensor ): OOD ground truth labels. Shape (M,). ood_logits ( torch.Tensor ): OOD logits. Shape (M, C). ood_feat ( torch.Tensor ): OOD features. Shape (M, D). fc_weight ( torch.Tensor ): FC layer weight. Shape (D, C). prototype ( torch.Tensor ): Prototype. Shape (D, C). tpr_th ( float ): True positive rate threshold to compute false positive rate. Default is 0.95. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is None. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution prot(id_gt, id_logits, ood_gt, ood_logits, prototypes: list, tpr_th=0.95, prec_th=None) Prototype-based (Prot) method for OOD detection. Parameters: id_gt ( torch.Tensor ): ID ground truth labels, shape (N,). id_logits ( list of torch.Tensor ): ID logits, containing shape (N, C). ood_gt ( torch.Tensor ): OOD ground truth labels, shape (M,). ood_logits ( list of torch.Tensor ): OOD logits, containing shape (M, C). prototypes ( list of torch.Tensor ): Prototypes, containing shape (D, C). tpr_th ( float ): True positive rate threshold to compute false positive rate. prec_th ( float ): Precision threshold for searching threshold. If None, not searching for threshold. Default is Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution","title":"ncdia.algorithms.ood.methods.py"},{"location":"ncdia/#ncdiaalgorithmsoodinferencepy","text":"The inference version of implemented ood methods in ncdia.algorithms.ood.methods.py","title":"ncdia.algorithms.ood.inference.py"},{"location":"ncdia/#ncdiaalgorithmsoodmetricspy","text":"ood_metrics(conf, label, tpr_th=0.95) Compute OOD metrics. Parameters: conf ( np.ndarray ): Confidence scores. Shape (N,). label ( np.ndarray ): Label array. Shape (N,). Containing: -1: OOD samples. int >= 0: ID samples with class labels tpr_th ( float ): True positive rate threshold to compute false positive rate. Returns: fpr ( float ): False positive rate. auroc ( float ): Area under the ROC curve. aupr_in ( float ): Area under the precision-recall curve for in-distribution samples. aupr_out ( float ): Area under the precision-recall curve for out-of-distribution samples. search_threshold(conf, label, prec_th) Search for the threshold for OOD detection. Parameters: conf ( np.ndarray ): Confidence scores. Shape (N,). label ( np.ndarray ): Label array. Shape (N,). Containing: -1: OOD samples. int >= 0: ID samples with class labels prec_th ( float ): Precision threshold. Returns: best_th ( float ): Threshold for OOD detection. prec ( float ): Precision at the threshold. recall ( float ): Recall at the threshold.","title":"ncdia.algorithms.ood.metrics.py"},{"location":"ncdia/#ncdiaalgorithmssupervisedstandardpy","text":"Modules related to supervised learning","title":"ncdia.algorithms.supervised.standard.py"},{"location":"ncdia/#standardsl","text":"Class inherits from BaseAlg . Standard supervised learning algorithm train_step(self, trainer, data, label, *args, **kwargs) Training step for standard supervised learning. Parameters: trainer ( object ): Trainer object. data ( torch.Tensor ): Input data. label ( torch.Tensor ): Label data. args ( tuple ): Additional arguments. kwargs ( dict ): Additional keyword arguments. Returns: results ( dict ): Training results. Contains the following keys: \"loss\" : Loss value. \"acc\" : Accuracy value. val_step(self, trainer, data, label, *args, **kwargs) Validation step for standard supervised learning. Parameters: trainer ( object ): Trainer object. data ( torch.Tensor ): Input data. label ( torch.Tensor ): Label data. args ( tuple ): Additional arguments. kwargs ( dict ): Additional keyword arguments. Returns: results ( dict ): Validation results. Contains the following: \"loss\" : Loss value. \"acc\" : Accuracy value. test_step(self, trainer, data, label, *args, **kwargs) Test step for standard supervised learning. Parameters: trainer (object): Trainer object. data (torch.Tensor): Input data. label (torch.Tensor): Label data. args (tuple): Additional arguments. kwargs (dict): Additional keyword arguments. Returns: results ( dict ): Test results. Contains the following: \"loss\" : Loss value. \"acc\" : Accuracy value.","title":"StandardSL"},{"location":"ncdia/#ncdiadataloader","text":"","title":"ncdia.dataloader"},{"location":"ncdia/#ncdiadataloaderbasepy","text":"build_dataloader(kwargs) Build data loader. Parameters: kwargs ( dict ): Arguments for DataLoader. Contains the following: dataset ( dict ): Dataset configuration. other arguments for DataLoader, such as batch_size , shuffle , etc. Returns: loader ( DataLoader ): Data loader.","title":"ncdia.dataloader.base.py"},{"location":"ncdia/#ncdiadataloadertoolspy","text":"Implements some of the commonly used dataloaders","title":"ncdia.dataloader.tools.py"},{"location":"ncdia/#ncdiadataloaderdatasets","text":"Implements some of the commonly used datasets, including: CIFAR100 CUB200 Caltech101 Food101 ImageNet ImageNetR BM200","title":"ncdia.dataloader.datasets"},{"location":"ncdia/#ncdiadataloaderaugmentations","text":"Implements some of the commonly used augmentation methods.","title":"ncdia.dataloader.augmentations"},{"location":"ncdia/#ncdiamodel","text":"","title":"ncdia.model"},{"location":"ncdia/#ncdiamodelsmodelspy","text":"get_network(config) load model. Parameters: - trainer ( config ): model config","title":"ncdia.models.models.py"},{"location":"ncdia/#ncdiamodelsnetinc_netpy","text":"","title":"ncdia.models.net.inc_net.py"},{"location":"ncdia/#basenet","text":"BaseNet for incremental learning. __init__(self, network, base_classes, num_classes, att_classes, net_alice, mode) The constructor method that initializes an instance of BaseNet . Parameters: network ( config ): The config of the network. base_classes ( int ): The number of base classes. num_classes ( int ): The total class number. att_classes ( int ): The attribute class number. mode ( str ): classifier mode. feature_dim(self) The feature dimension of the network. Returns: out_dim ( int ) feature dimension of the network. extractor_vector(self, x) get features of input x. Parameters: x ( tensor ): input data. Returns: out_features ( tensor ) features of the input. forward(self, x) forworad pass of the network. Parameters: x ( tensor ): input data. Returns: results ( dict ): forward pass results. Contains the following keys: \"fmaps\" : [x_1, x_2, ..., x_n], \"features\" : features \"logits\" : logits copy(self) copy. Returns: copy function . freeze(self) freeze parameters.","title":"BaseNet"},{"location":"ncdia/#incrementalnet","text":"Incremental Network which follows BaseNet. __init__(self, network, base_classes, num_classes, att_classes, net_alice, mode) The constructor method that initializes an instance of BaseNet . Parameters: network ( config ): The config of the network. base_classes ( int ): The number of base classes. num_classes ( int ): The total class number. att_classes ( int ): The attribute class number. mode ( str ): classifier mode. update_fc(self, nb_classes) update fc parameter, generate new fc and copy old parameter. Parameters: network ( int ): New class number. Returns: fc : updated fc layers. generate_fc(self, in_dim, out_dim) Parameters: in_dim ( int ): new fc in dimension. out_dim ( int ): new fc out dimension. Returns: fc : new fc layers. forward(self, x) forworad pass of the network. Parameters: x ( tensor ): input data. Returns: results ( dict ): forward pass results. Contains the following keys: \"fmaps\" : [x_1, x_2, ..., x_n], \"features\" : features \"logits\" : logits weight_align(self, increment) normalize classifer parameters. Parameters: increment ( int ): incremental classes.","title":"IncrementalNet"},{"location":"ncdia/#ncdiatrainers","text":"","title":"ncdia.trainers"},{"location":"ncdia/#ncdiatrainersbasepy","text":"","title":"ncdia.trainers.base.py"},{"location":"ncdia/#basetrainer","text":"Basic trainer class for training models. Attributes: model ( nn.Module ): Neural network models. train_loader ( DataLoader ): DataLoader for training. val_loader ( DataLoader ): DataLoader for validation. test_loader ( DataLoader ): DataLoader for testing. optimizer ( Optimizer ): Optimizer. scheduler ( lr_scheduler._LRScheduler ): Learning rate scheduler. criterion ( Callable ): Criterion for training. algorithm ( object ): Algorithm for training. metrics ( dict ): Metrics for evaluation and testing. session ( int ): Session number. max_epochs ( int ): Total epochs for training. max_train_iters ( int ): Iterations on one epoch for training. max_val_iters ( int ): Iterations on one epoch for validation. max_test_iters ( int ): Iterations on one epoch for testing. epoch ( int ): Current training epoch. iter ( int ): Current iteration or index of the current batch. cfg ( Configs ): Configuration for trainer. hooks ( List[Hook] ): List of registered hooks. logger ( Logger ): Logger for logging information. device ( torch.device ): Device to use. work_dir ( str ): Working directory to save logs and checkpoints. exp_name ( str ): Experiment name. load_from ( str ): Checkpoint file path to load. Methods: __init__(self, cfg, session, model, train_loader, val_loader, test_loader, default_hooks, custom_hooks, load_from, exp_name, work_dir) The constructor method that initializes an instance of BaseTrainer . Parameters: cfg ( dict, optional ): Configuration for trainer, Contains: 'trainer' ( dict ): 'type' ( str ): Type of trainer. 'algorithm' ( dict ): 'type' ( str ): Type of algorithm. 'criterion' ( dict ): 'type' ( str ): Type of criterion for training. 'optimizer' : 'type' ( str ): Name of optimizer. 'param_groups' ( dict | None ): If provided, directly optimize param_groups and abandon model. kwargs ( dict ) for optimizer, such as 'lr', 'weight_decay', etc. 'scheduler' : 'type' ( str ): Name of scheduler. kwargs ( dict ) for scheduler, such as 'step_size', 'gamma', etc. 'device' ( str | torch.device | None ): Device to use. If None, use 'cuda' if available. 'trainloader' : 'dataset': 'type' ( str ): Type of dataset. kwargs ( dict ) for dataset, such as 'root', 'split', etc. kwargs ( dict ) for DataLoader, such as 'batch_size', 'shuffle', etc. 'valloader' : 'dataset': 'type' ( str ): Type of dataset. kwargs ( dict ) for dataset, such as 'root', 'split', etc. kwargs ( dict ) for DataLoader, such as 'batch_size', 'shuffle', etc. 'testloader' : 'dataset': 'type' ( str ): Type of dataset. kwargs ( dict ) for dataset, such as 'root', 'split', etc. kwargs ( dict ) for DataLoader, such as 'batch_size', 'shuffle', etc. 'exp_name' ( str ): Experiment name. 'work_dir' ( str ): Working directory to save logs and checkpoints. session ( int ): Session number. If == 0, execute pre-training. If > 0, execute incremental training. model ( nn.Module ): Model to be trained. train_loader ( DataLoader | dict, optional ): DataLoader for training. val_loader ( DataLoader | dict, optional ): DataLoader for validation. test_loader ( DataLoader | dict, optional ): DataLoader for testing. default_hooks ( dict, optional ): Default hooks to be registered. custom_hooks ( list, optional ): Custom hooks to be registered. load_from ( str, optional ): Checkpoint file path to load. work_dir ( str, optional ): Working directory to save logs and checkpoints. train_step(self, batch, **kwargs) Training step. This method should be implemented in subclasses. Parameters: batch ( dict | tuple | list ): A batch of data from the data loader. Returns: results (dict): Contains the following: {\"key1\": value1, \"key2\": value2,...} keys denote the description of the value, such as \"loss\" , \"acc\" , \"ccr\" , etc. values are the corresponding values of the keys, can be int , float , str , etc. val_step(self, batch, kwargs)** Validation step. This method should be implemented in subclasses. Parameters: batch ( dict | tuple | list ): A batch of data from the data loader. Returns: results (dict): Contains the following: {\"key1\": value1, \"key2\": value2,...} keys denote the description of the value, such as \"loss\" , \"acc\" , \"ccr\" , etc. values are the corresponding values of the keys, can be int , float , str , etc. test_step(self, batch, kwargs)** Test step. This method should be implemented in subclasses. Parameters: batch ( dict | tuple | list ): A batch of data from the data loader. Returns: results (dict): Contains the following: {\"key1\": value1, \"key2\": value2,...} keys denote the description of the value, such as \"loss\" , \"acc\" , \"ccr\" , etc. values are the corresponding values of the keys, can be int , float , str , etc. train(self) Launch the training process. Returns: model ( nn.Module ): Trained model. val(self) Validation process. test(self) Test process. load_ckpt(self, fpath, device='cpu') Load checkpoint from file. Parameters: fpath ( str ): Checkpoint file path. device ( str ): Device to load checkpoint. Defaults to 'cpu'. Returns: model ( nn.Module ): Loaded model. save_ckpt(self, fpath) Save checkpoint to file. Parameters: fpath ( str ): Checkpoint file path. call_hook(self, fn_name: str, kwargs)** Call all hooks with the specified function name. Parameters: fn_name ( str ): Function name to be called, such as: 'before_train_epoch' 'after_train_epoch' 'before_train_iter' 'after_train_iter' 'before_val_epoch' 'after_val_epoch' 'before_val_iter' 'after_val_iter' kwargs ( dict ): Arguments for the function. register_hook(self, hook, priority=None) Register a hook into the hook list. The hook will be inserted into a priority queue, with the specified priority (See :class: Priority for details of priorities). For hooks with the same priority, they will be triggered in the same order as they are registered. Priority of hook will be decided with the following priority: priority argument. If priority is given, it will be priority of hook. If hook argument is a dict and priority in it, the priority will be the value of hook['priority'] . If hook argument is a dict but priority not in it or hook is an instance of hook , the priority will be hook.priority . Parameters: hook ( :obj: Hook or dict ): The hook to be registered. priority (int or str or :obj: Priority , optional): Hook priority. Lower value means higher priority. register_default_hooks(self, hooks=None) Register default hooks into hook list. hooks will be registered into runner to execute some default actions like updating model parameters or saving checkpoints. Default hooks and their priorities: Hooks Priority RuntimeInfoHook VERY_HIGH (10) IterTimerHook NORMAL (50) DistSamplerSeedHook NORMAL (50) LoggerHook BELOW_NORMAL (60) ParamSchedulerHook LOW (70) CheckpointHook VERY_LOW (90) If hooks is None, above hooks will be registered by default: default_hooks = dict( logger=dict(type='LoggerHook'), model=dict(type='ModelHook'), alg=dict(type='AlgHook'), optimizer = dict(type='OptimizerHook'), scheduler = dict(type='SchedulerHook'), metric = dict(type='MetricHook'), ) If not None, hooks will be merged into default_hooks . If there are None value in default_hooks, the corresponding item will be popped from default_hooks : hooks = dict(timer=None) The final registered default hooks will be :obj: RuntimeInfoHook , :obj: DistSamplerSeedHook , :obj: LoggerHook , :obj: ParamSchedulerHook and :obj: CheckpointHook . Parameters: hooks ( dict[str, Hook or dict] ): Default hooks or configs to be registered. register_custom_hooks(self, hooks) Register custom hooks into hook list. Parameters: hooks ( list[Hook | dict] ): List of hooks or configs to be registered. register_hooks(self, default_hooks=None, custom_hooks=None) Register default hooks and custom hooks into hook list. Parameters: default_hooks ( dict[str, dict] or dict[str, Hook] ): Hooks to execute default actions like updating model parameters and saving checkpoints. Defaults to None. custom_hooks ( list[dict] or list[Hook] ): Hooks to execute custom actions like visualizing images processed by pipeline. Defaults to None. get_hooks_info(self) Get registered hooks information. Returns: info ( str ): Information of registered hooks.","title":"BaseTrainer"},{"location":"ncdia/#ncdiatrainerspretrainerpy","text":"","title":"ncdia.trainers.pretrainer.py"},{"location":"ncdia/#pretrainer","text":"PreTrainer class for pre-training a model on session 0. Attributes: max_epochs ( int ): Total epochs for training. Methods: __init__(self, max_epochs=1, **kwargs): The constructor method that initializes an instance of PreTrainer . max_epochs ( int ): Total epochs for training. train_step(self, batch, **kwargs): Training step. val_step(self, batch, **kwargs): Validation step. test_step(self, batch, **kwargs): Test step. batch_parser(batch) Parse a batch of data. Parameters: batch ( dict | tuple | list ): A batch of data. Returns: data ( torch.Tensor | list ): Input data. label ( torch.Tensor | list ): Label data. attribute ( torch.Tensor | list ): Attribute data. imgpath ( list of str ): Image path.","title":"PreTrainer"},{"location":"ncdia/#ncdiatrainersinctrainerpy","text":"","title":"ncdia.trainers.inctrainer.py"},{"location":"ncdia/#inctrainer","text":"IncTrainer class for incremental training. Attributes: sess_cfg ( Configs ): Session configuration. num_sess ( int ): Number of sessions. session ( int ): Session number. If == 0, execute pre-training. If > 0, execute incremental training. hist_trainset ( MergedDataset ): Historical training dataset. hist_valset ( MergedDataset ): Historical validation dataset. hist_testset ( MergedDataset ): Historical testing dataset. Methods: __init__(self, cfg=None, sess_cfg=None, ncd_cfg=None, session=0, model=None, hist_trainset=None, hist_testset=None, old_model=None, **kwargs) The constructor method that initializes an instance of IncTrainer . Parameters: model ( nn.Module ): Model to be trained. cfg ( dict ): Configuration for trainer. sess_cfg ( Configs ): Session configuration. session ( int ): Session number. Default: 0. train(self) Incremental training. self.num_sess determines the number of sessions, and session number is stored in self.session . Returns: model ( nn.Module ): Trained model.","title":"IncTrainer"},{"location":"ncdia/#ncdiatrainershooks","text":"Implements some of the commonly used hooks.","title":"ncdia.trainers.hooks"},{"location":"ncdia/#hook","text":"ncdia.trainers.hooks.hook.py Base hook class. All hooks should inherit from this class.","title":"Hook"},{"location":"ncdia/#alghook","text":"ncdia.trainers.hooks.alghook.py A hook to modify algorithm state in the pipeline. This class is a base class for all algorithm hooks.","title":"AlgHook"},{"location":"ncdia/#loggerhook","text":"ncdia.trainers.hooks.loggerhook.py A hook to log information during training and evaluation.","title":"LoggerHook"},{"location":"ncdia/#metrichook","text":"ncdia.trainers.hooks.metrichook.py A hook to calculate metrics during evaluation and testing.","title":"MetricHook"},{"location":"ncdia/#modelhook","text":"ncdia.trainers.hooks.modelhook.py A hook to change model state in the pipeline, such as setting device, changing model to eval mode, etc.","title":"ModelHook"},{"location":"ncdia/#ncdhook","text":"ncdia.trainers.hooks.ncdhook.py A hook to execute OOD and NCD detection to relabel data","title":"NCDHook"},{"location":"ncdia/#optimizerhook","text":"ncdia.trainers.hooks.optimizerhook.py A hook to put optimizer to zero_grad and step during training.","title":"OptimizerHook"},{"location":"ncdia/#schedulerhook","text":"ncdia.trainers.hooks.schedulerhook.py A hook to change learning rate during training.","title":"SchedulerHook"},{"location":"ncdia/#ncdiatrainersoptims","text":"","title":"ncdia.trainers.optims"},{"location":"ncdia/#ncdiatrainersoptimsoptimizerpy","text":"build_optimizer(type, model, param_groups=None, **kwargs) Build optimizer. Parameters: type ( str ): type of optimizer model ( nn.Module | dict ): model or param_groups param_groups ( dict | None ): if provided, directly optimize param_groups and abandon model kwargs ( dict ): arguments for optimizer Returns: optimizer ( torch.optim.Optimizer ): optimizer","title":"ncdia.trainers.optims.optimizer.py"},{"location":"ncdia/#ncdiatrainersoptimsschedulerpy","text":"Implements some of the commonly used scheduler. CosineWarmupLR LinearWarmupLR ConstantLR Methods: build_scheduler(type, optimizer, **kwargs) Build learning rate scheduler. Parameters: type ( str ): type of scheduler optimizer (t orch.optim.Optimizer ): optimizer kwargs ( dict ): arguments for scheduler Returns: lr_scheduler ( torch.optim.lr_scheduler._LRScheduler ): learning rate scheduler","title":"ncdia.trainers.optims.scheduler.py"},{"location":"ncdia/#ncdiatrainerspriority","text":"Hook priority levels.","title":"ncdia.trainers.priority"},{"location":"ncdia/#priority","text":"Level Value HIGHEST 0 VERY_HIGH 10 HIGH 30 ABOVE_NORMAL 40 NORMAL 50 BELOW_NORMAL 60 LOW 70 VERY_LOW 90 LOWEST 100","title":"Priority"},{"location":"ncdia/#ncdiautils","text":"","title":"ncdia.utils"},{"location":"ncdia/#ncdiautilsmetrics","text":"","title":"ncdia.utils.metrics"},{"location":"ncdia/#ncdiautilsmetricsaccuracypy","text":"accuracy(output, target, topk=(1,)) Computes the accuracy over the k-top predictions for the specified values of k. Parameters: output ( torch.Tensor ): model output, shape (batch_size, num_classes) target ( torch.Tensor ): target labels, shape (batch_size) topk ( tuple ): top-k values, default is (1,) Returns: acc ( list ): accuracy values for each k in topk per_class_accuracy(output, target, topk=(1, )) Compute per class accuracy over the k-top predictions for the specified values of k Parameters: output ( torch.Tensor ): model output, shape (batch_size, num_classes) target ( torch.Tensor ): target labels, shape (batch_size) topk ( tuple ): top-k values, default is (1,) Returns: acc ( list ): accuracy values for each k in topk","title":"ncdia.utils.metrics.accuracy.py"},{"location":"ncdia/#ncdiautilsmetricsmeterpy","text":"AverageMeter Computes and stores the average and current value.","title":"ncdia.utils.metrics.meter.py"},{"location":"ncdia/#ncdiautilslosses","text":"","title":"ncdia.utils.losses"},{"location":"ncdia/#crossentropyloss","text":"In crossentropy.py . CrossEntropyLoss with label smoothing.","title":"CrossEntropyLoss"},{"location":"ncdia/#angularpenaltysmloss","text":"In angular.py . Angular Penalty Softmax Loss. Three 'loss_types' available: ['arcface', 'sphereface', 'cosface']","title":"AngularPenaltySMLoss"},{"location":"ncdia/#ncdiautilscfgpy","text":"","title":"ncdia.utils.cfg.py"},{"location":"ncdia/#configs","text":"Include implementation of setup and use of configs.","title":"Configs"},{"location":"ncdia/#ncdiautilsloggerpy","text":"Include implementation of loggers to write output to console and external text file.","title":"ncdia.utils.logger.py"},{"location":"ncdia/#ncdiautilsregistrypy","text":"","title":"ncdia.utils.registry.py"},{"location":"ncdia/#registry","text":"A registry to map strings to classes or functions. Examples: >>> REGISTRY = Registry() >>> @REGISTRY >>> def foo(): >>> return 'foo' >>> @REGISTRY.register >>> def bar(): >>> return 'bar' >>> print(REGISTRY['foo']()) foo >>> print(REGISTRY['bar']()) bar >>> print(REGISTRY) {'foo': <function foo at 0x7f9b1c0e0d30>, 'bar': <function bar at 0x7f9b1c0e0e18>} >>> print(REGISTRY['foo']) <function foo at 0x7f9b1c0e0d30> >>> print(REGISTRY['bar']) <function bar at 0x7f9b1c0e0e18> >>> print('foo' in REGISTRY) True >>> print('bar' in REGISTRY) True >>> print('foobar' in REGISTRY) False >>> print(REGISTRY.keys()) dict_keys(['foo', 'bar']) >>> print(REGISTRY.values()) dict_values([<function foo at 0x7f9b1c0e0d30>, <function bar at 0x7f9b1c0e0e18>]) >>> print(REGISTRY.items()) dict_items([('foo', <function foo at 0x7f9b1c0e0d30>), ('bar', <function bar at 0x7f9b1c0e0e18>)]) >>> print(len(REGISTRY)) 2 register_callable(self, target: callable) Register a target. Parameters: target ( callable ): callable target to be registered. register_dict(self, target) Register a dict. Parameters: target ( dict ): A dict to be registered. All its values should be callable. register(self, target) Register a target. Parameters: target ( callable | dict ): target to be registered. Returns: target ( object ): Registered target. build(self, target: dict | Configs, **kwargs) Build a target with configs. Parameters: target ( dict | Configs ): A dict to be built. It should have a key 'type' to specify the target type. It may have other keys to specify the target configs. kwargs ( dict ): Additional keyword arguments. Returns: target ( object ): A built target.","title":"Registry"},{"location":"ncdia/#ncdiautilstoolspy","text":"mkdir_if_missing(dirname) Create dirname if it is missing. Parameters: dirname ( str ): directory path auto_device(device) Automatically set the device for the input tensor. Parameters: device ( str | torch.device | None ): device name or device object. If None, return torch.device('cuda') if available, otherwise return torch.device('cpu'). set_random_seed(seed) Set random seed for reproducibility. Parameters: seed ( int ): random seed","title":"ncdia.utils.tools.py"},{"location":"overview/","text":"\ud83d\udcda OpenHAIV Documentation The framework adopts a modular design overall, which is reflected in two key aspects: Functionally , it independently incorporates dedicated modules for supervised training, out-of-distribution detection, novel class discovery, and incremental learning. Procedurally , the framework divides its operational workflow into distinct stages, including data processing, model construction, training \\& evaluation, and visualization. From an implementation perspective, the framework is built upon foundational deep learning, data processing, and visualization libraries such as PyTorch, NumPy, Matplotlib, and Pandas, leveraging their extensive built-in functionalities. This comprehensive framework provides researchers with a robust foundation for tackling open world learning challenges, from initial model training through continuous adaptation to novel scenarios. \u2b50 Key Features \ud83e\udde9 Modular Design Each component can be independently configured, tested, and replaced, enabling: Easy experimentation with different algorithms Seamless integration of new techniques Flexible deployment configurations \ud83d\ude80 Scalable Architecture The framework supports: Large-scale dataset processing Distributed training capabilities Efficient memory management Parallel processing optimization \ud83d\udd0c Extensible Framework Built for research and production use: Plugin-based algorithm integration Custom loss function support Flexible evaluation metrics Comprehensive logging and monitoring","title":"Overview"},{"location":"overview/#openhaiv-documentation","text":"The framework adopts a modular design overall, which is reflected in two key aspects: Functionally , it independently incorporates dedicated modules for supervised training, out-of-distribution detection, novel class discovery, and incremental learning. Procedurally , the framework divides its operational workflow into distinct stages, including data processing, model construction, training \\& evaluation, and visualization. From an implementation perspective, the framework is built upon foundational deep learning, data processing, and visualization libraries such as PyTorch, NumPy, Matplotlib, and Pandas, leveraging their extensive built-in functionalities. This comprehensive framework provides researchers with a robust foundation for tackling open world learning challenges, from initial model training through continuous adaptation to novel scenarios.","title":"\ud83d\udcda OpenHAIV Documentation"},{"location":"overview/#key-features","text":"","title":"\u2b50 Key Features"},{"location":"overview/#modular-design","text":"Each component can be independently configured, tested, and replaced, enabling: Easy experimentation with different algorithms Seamless integration of new techniques Flexible deployment configurations","title":"\ud83e\udde9 Modular Design"},{"location":"overview/#scalable-architecture","text":"The framework supports: Large-scale dataset processing Distributed training capabilities Efficient memory management Parallel processing optimization","title":"\ud83d\ude80 Scalable Architecture"},{"location":"overview/#extensible-framework","text":"Built for research and production use: Plugin-based algorithm integration Custom loss function support Flexible evaluation metrics Comprehensive logging and monitoring","title":"\ud83d\udd0c Extensible Framework"},{"location":"people/","text":"\ud83e\uddd1\u200d\ud83e\udd1d\u200d\ud83e\uddd1 OpemHAIV Authors \u2b50 Corresponding Author Xiang Xiang Google Scholar | Homepage | \u2709\ufe0f Email: xex@hust.edu.cn Xiang Xiang is currently an associate professor of Intelligence Science and Technology at Huazhong University of Science and Technology , Wuhan, China , where he founds and directs the HUST AIA Image and Vision Learning Lab (HAIV Lab) since 2021 , working on computer vision and open-world learning . He is a senior member of China Society of Image and Graphics (CSIG) , and also visiting with Peng Cheng Laborotory , Shenzhen, China . He has heavily published papers at venues such as CVPR, ICCV, ECCV, ICML, ACM Multimedia, MICCAI , etc., and been honorably mentioned twice for the AI 2000 Most Influential Scholar Award in recognition of outstanding and vibrant contributions in the field of multimedia in the past decade. He has been an applied scientist at AWS AI Labs , Seattle, USA , since 2018 , until moving to TuSimple , San Diego, USA , as a senior research scientist in 2020 . Before that, he received the B.S. degree from Wuhan University , Wuhan, China , in 2009 , the M.S. degree from Institute of Computing Technology, Chinese Academy of Sciences , Beijing, China , in 2012 , the M.S.E. and Ph.D. degrees from Johns Hopkins University , Baltimore, USA , in 2014 and 2018 , respectively, all in computer science. \ud83e\udd17 Other Authors Zhou Qinhao Zhou Qinhao received his B.S. degree from Northwestern Polytechnical University , Xi'an, China , in 2022, and his M.S. degree from the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China , in 2025. He is currently working at ByteDance , Beijing, China . Xu Zhuo Zhuo Xu has received the B.S. degree from Huazhong University of Science and Technology , Wuhan, China , in 2023. He is currently pursuing a M.S. degree at the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China . His research interests include open-set recognition and out-of-distribution detection. Ma Jing Ma Jing received his B.S. degree from Huazhong University of Science and Technology , Wuhan, China , in 2022, and his M.S. degree from the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China , in 2025. He is currently working at iFLYTEK , Hefei, China . Dai Jiaxin Dai Jiaxin has received the B.S. degree from Huazhong University of Science and Technology , Wuhan, China , in 2025. He is currently pursuing a M.S. degree at the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China . Liang Yifan Liang Yifan has received the B.S. degree from Huazhong University of Science and Technology , Wuhan, China , in 2025. He is currently pursuing a M.S. degree at the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China . Li Hanlin Li Hanlin has received the B.S. degree from Huazhong University of Science and Technology , Wuhan, China , in 2025. He is currently pursuing a M.S. degree at the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China . \ud83d\ude4f Special Thanks We would like to express our special gratitude to the following contributors who have graduated but made significant contributions to this project: Zhang Zihan : received both B.S. and M.S. degrees from the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China . He is currently working at China Mobile Zhejiang Innovation Institute , Hangzhou, China . Tan Yuwen : received both B.S. and M.S. degrees from the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China . He is currently pursuing a Ph.D. in Computer Science and Technology at Boston University , Boston, USA , supervised by Prof. Gong Boqi.","title":"People"},{"location":"people/#opemhaiv-authors","text":"","title":"\ud83e\uddd1\u200d\ud83e\udd1d\u200d\ud83e\uddd1 OpemHAIV Authors"},{"location":"people/#corresponding-author","text":"Xiang Xiang Google Scholar | Homepage | \u2709\ufe0f Email: xex@hust.edu.cn Xiang Xiang is currently an associate professor of Intelligence Science and Technology at Huazhong University of Science and Technology , Wuhan, China , where he founds and directs the HUST AIA Image and Vision Learning Lab (HAIV Lab) since 2021 , working on computer vision and open-world learning . He is a senior member of China Society of Image and Graphics (CSIG) , and also visiting with Peng Cheng Laborotory , Shenzhen, China . He has heavily published papers at venues such as CVPR, ICCV, ECCV, ICML, ACM Multimedia, MICCAI , etc., and been honorably mentioned twice for the AI 2000 Most Influential Scholar Award in recognition of outstanding and vibrant contributions in the field of multimedia in the past decade. He has been an applied scientist at AWS AI Labs , Seattle, USA , since 2018 , until moving to TuSimple , San Diego, USA , as a senior research scientist in 2020 . Before that, he received the B.S. degree from Wuhan University , Wuhan, China , in 2009 , the M.S. degree from Institute of Computing Technology, Chinese Academy of Sciences , Beijing, China , in 2012 , the M.S.E. and Ph.D. degrees from Johns Hopkins University , Baltimore, USA , in 2014 and 2018 , respectively, all in computer science.","title":"\u2b50 Corresponding Author"},{"location":"people/#other-authors","text":"Zhou Qinhao Zhou Qinhao received his B.S. degree from Northwestern Polytechnical University , Xi'an, China , in 2022, and his M.S. degree from the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China , in 2025. He is currently working at ByteDance , Beijing, China . Xu Zhuo Zhuo Xu has received the B.S. degree from Huazhong University of Science and Technology , Wuhan, China , in 2023. He is currently pursuing a M.S. degree at the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China . His research interests include open-set recognition and out-of-distribution detection. Ma Jing Ma Jing received his B.S. degree from Huazhong University of Science and Technology , Wuhan, China , in 2022, and his M.S. degree from the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China , in 2025. He is currently working at iFLYTEK , Hefei, China . Dai Jiaxin Dai Jiaxin has received the B.S. degree from Huazhong University of Science and Technology , Wuhan, China , in 2025. He is currently pursuing a M.S. degree at the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China . Liang Yifan Liang Yifan has received the B.S. degree from Huazhong University of Science and Technology , Wuhan, China , in 2025. He is currently pursuing a M.S. degree at the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China . Li Hanlin Li Hanlin has received the B.S. degree from Huazhong University of Science and Technology , Wuhan, China , in 2025. He is currently pursuing a M.S. degree at the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China .","title":"\ud83e\udd17 Other Authors"},{"location":"people/#special-thanks","text":"We would like to express our special gratitude to the following contributors who have graduated but made significant contributions to this project: Zhang Zihan : received both B.S. and M.S. degrees from the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China . He is currently working at China Mobile Zhejiang Innovation Institute , Hangzhou, China . Tan Yuwen : received both B.S. and M.S. degrees from the School of Artificial Intelligence and Automation, Huazhong University of Science and Technology , Wuhan, China . He is currently pursuing a Ph.D. in Computer Science and Technology at Boston University , Boston, USA , supervised by Prof. Gong Boqi.","title":"\ud83d\ude4f Special Thanks"},{"location":"quik/","text":"\ud83d\ude80 Getting Started \ud83d\udce6 Installation It is recommended to use anaconda3 to manage and maintain the python library environment. Download the .sh file from the anaconda3 website Install anaconda3 with .sh file bash Anaconda3-2023.03-Linux-x86_64.sh \ud83d\udd27 Environment Setup Create and activate a virtual environment: conda create -n openhaiv python=3.10 -y conda activate openhaiv pip install -r requirements.txt python setup.py install Required packages: * pytorch>=1.12.0 torchvision>=0.13.0 (recommend official torch command) * numpy>=1.26.4 * scipy>=1.14.0 * scikit-learn>=1.5.1 \ud83c\udfc3\u200d\u2642\ufe0f Running Examples Out-of-Distribution Detection python ncdia/train.py --cfg configs/pipeline/ood_detection/msp/det_oes_rn50_msp_train.yaml --opts device='cuda:0' Class-incremental Learning bash ./scripts/inc_BM200_lwf.sh Novel Class Discovery # Set required parameters # - model weight in weight_path # - id_txt_file and ood_txt_file # - output_dir python ncd.py","title":"Quik Start"},{"location":"quik/#getting-started","text":"","title":"\ud83d\ude80 Getting Started"},{"location":"quik/#installation","text":"It is recommended to use anaconda3 to manage and maintain the python library environment. Download the .sh file from the anaconda3 website Install anaconda3 with .sh file bash Anaconda3-2023.03-Linux-x86_64.sh","title":"\ud83d\udce6 Installation"},{"location":"quik/#environment-setup","text":"Create and activate a virtual environment: conda create -n openhaiv python=3.10 -y conda activate openhaiv pip install -r requirements.txt python setup.py install Required packages: * pytorch>=1.12.0 torchvision>=0.13.0 (recommend official torch command) * numpy>=1.26.4 * scipy>=1.14.0 * scikit-learn>=1.5.1","title":"\ud83d\udd27 Environment Setup"},{"location":"quik/#running-examples","text":"Out-of-Distribution Detection python ncdia/train.py --cfg configs/pipeline/ood_detection/msp/det_oes_rn50_msp_train.yaml --opts device='cuda:0' Class-incremental Learning bash ./scripts/inc_BM200_lwf.sh Novel Class Discovery # Set required parameters # - model weight in weight_path # - id_txt_file and ood_txt_file # - output_dir python ncd.py","title":"\ud83c\udfc3\u200d\u2642\ufe0f Running Examples"},{"location":"results/","text":"\ud83d\udcca Results \ud83c\udf0d Open World Learning Table 1. The experiments of OWL on OpenEarthSensing dataset. ID Acc and ODD Acc are the in-distribution and out-of-distribution performance, respectively, and Avg denotes the average performance of each session. OOD Method CIL Method ID Acc OOD Acc Session 1 Session 2 Avg MSP LwF 91.17 55.01 91.27 42.11 66.69 EWC 91.17 55.01 91.27 28.89 60.08 iCaRL 91.17 55.01 91.27 50.29 70.78 MLS LwF 90.6 63.85 91.27 44.09 67.68 EWC 90.6 63.85 91.27 29.83 60.55 iCaRL 90.6 63.85 91.27 51.33 71.30 VIM LwF 93.5 59.99 91.27 43.49 67.38 EWC 93.5 59.99 91.27 31.33 61.30 iCaRL 93.5 59.99 91.27 33.78 62.52 \ud83c\udf31 Incremental Learning Fig 1. Experimental results of CIL. The left figure presents results in randomized order, while the right figure displays systematically organized results arranged from coarse to fine granularity. \ud83e\udde9 Few-Shot Class-Incremental Learning Table 2. The experimental results of few-shot class-incremental learning on the OpenEarthSensing dataset. Shots denote the training samples for each category. 50-shot 10-shot 5-shot 1-shot Last Avg Last Avg Last Avg Last Avg Alice 59.54 64.66 59.17 68.64 58.82 68.35 58.94 68.4 FACT 46.42 49.21 46.38 49.15 46.36 49.15 46.37 49.15 SAVC 71.71 79.55 72.23 80.07 66.61 75.17 59.63 76.77 \ud83d\udea8 Out-of-Distribution Detection CNN-based Methods Table 3. OOD detection performance on OES benchmark. 'Near' represents the average AUROC for Near-OOD datasets, 'Far' indicates the average AUROC for Far-OOD datasets. Method Standard Res Bias Aerial MSRGB IR Near Far Near Far Near Far Near Far Near Far MSP 88.42 93.91 66.51 78.4 54.38 56.85 65.50 66.92 61.47 65.35 ODIN 87.14 95.79 67.09 75.2 52.85 57.04 66.55 61.55 62.11 73.28 MDS 83.15 96.54 53.86 84.71 48.79 54.76 66.31 81.78 83.64 57.74 MLS 88.59 96.12 66.44 83.17 53.93 59.78 64.46 63.37 62.49 67.06 VIM 90.35 98.75 60.33 83.93 50.69 59.72 64.90 81.75 57.65 51.08 FBDB 90.24 98.17 66.64 87.87 54.49 60.41 59.45 74.49 61.40 68.62 VOS 86.19 95.68 63.37 81.32 51.10 60.01 59.77 58.72 59.47 60.26 LogiNorm 89.00 95.15 68.80 80.29 53.25 56.72 77.69 55.43 64.12 63.97 DML 84.38 90.36 65.78 76.16 52.89 58.60 62.56 50.68 60.39 50.56 CLIP-based Methods Table 4. CLIP based methods' performance on OES benchmark. 'Near' represents the average AUROC for Near-OOD datasets, 'Far' indicates the average AUROC for Far-OOD datasets. Method Standard Res Bias Aerial MSRGB IR Near Far Near Far Near Far Near Far Near Far MaxLogits 53.31 43.95 68.99 63.32 64.73 40.46 68.22 9.34 62.73 37.00 MCM 61.79 52.60 59.97 51.94 66.07 67.85 58.90 55.89 54.41 40.43 GLMCM 62.07 52.33 59.20 51.57 65.20 67.42 57.32 56.89 51.75 42.30 CoOp 86.04 94.21 64.09 73.36 61.22 76.40 66.73 90.22 61.30 45.16 LoCoOp 85.71 90.94 66.20 71.67 64.18 76.52 69.64 86.28 61.41 43.33 SCT 85.56 90.78 65.37 70.30 64.14 77.67 68.58 86.41 60.81 42.48 DPM 91.19 99.24 68.60 92.61 60.50 71.26 74.66 93.56 65.11 75.10","title":"Results"},{"location":"results/#results","text":"","title":"\ud83d\udcca Results"},{"location":"results/#open-world-learning","text":"Table 1. The experiments of OWL on OpenEarthSensing dataset. ID Acc and ODD Acc are the in-distribution and out-of-distribution performance, respectively, and Avg denotes the average performance of each session. OOD Method CIL Method ID Acc OOD Acc Session 1 Session 2 Avg MSP LwF 91.17 55.01 91.27 42.11 66.69 EWC 91.17 55.01 91.27 28.89 60.08 iCaRL 91.17 55.01 91.27 50.29 70.78 MLS LwF 90.6 63.85 91.27 44.09 67.68 EWC 90.6 63.85 91.27 29.83 60.55 iCaRL 90.6 63.85 91.27 51.33 71.30 VIM LwF 93.5 59.99 91.27 43.49 67.38 EWC 93.5 59.99 91.27 31.33 61.30 iCaRL 93.5 59.99 91.27 33.78 62.52","title":"\ud83c\udf0d Open World Learning"},{"location":"results/#incremental-learning","text":"Fig 1. Experimental results of CIL. The left figure presents results in randomized order, while the right figure displays systematically organized results arranged from coarse to fine granularity.","title":"\ud83c\udf31 Incremental Learning"},{"location":"results/#few-shot-class-incremental-learning","text":"Table 2. The experimental results of few-shot class-incremental learning on the OpenEarthSensing dataset. Shots denote the training samples for each category. 50-shot 10-shot 5-shot 1-shot Last Avg Last Avg Last Avg Last Avg Alice 59.54 64.66 59.17 68.64 58.82 68.35 58.94 68.4 FACT 46.42 49.21 46.38 49.15 46.36 49.15 46.37 49.15 SAVC 71.71 79.55 72.23 80.07 66.61 75.17 59.63 76.77","title":"\ud83e\udde9 Few-Shot Class-Incremental Learning"},{"location":"results/#out-of-distribution-detection","text":"","title":"\ud83d\udea8 Out-of-Distribution Detection"},{"location":"results/#cnn-based-methods","text":"Table 3. OOD detection performance on OES benchmark. 'Near' represents the average AUROC for Near-OOD datasets, 'Far' indicates the average AUROC for Far-OOD datasets. Method Standard Res Bias Aerial MSRGB IR Near Far Near Far Near Far Near Far Near Far MSP 88.42 93.91 66.51 78.4 54.38 56.85 65.50 66.92 61.47 65.35 ODIN 87.14 95.79 67.09 75.2 52.85 57.04 66.55 61.55 62.11 73.28 MDS 83.15 96.54 53.86 84.71 48.79 54.76 66.31 81.78 83.64 57.74 MLS 88.59 96.12 66.44 83.17 53.93 59.78 64.46 63.37 62.49 67.06 VIM 90.35 98.75 60.33 83.93 50.69 59.72 64.90 81.75 57.65 51.08 FBDB 90.24 98.17 66.64 87.87 54.49 60.41 59.45 74.49 61.40 68.62 VOS 86.19 95.68 63.37 81.32 51.10 60.01 59.77 58.72 59.47 60.26 LogiNorm 89.00 95.15 68.80 80.29 53.25 56.72 77.69 55.43 64.12 63.97 DML 84.38 90.36 65.78 76.16 52.89 58.60 62.56 50.68 60.39 50.56","title":"CNN-based Methods"},{"location":"results/#clip-based-methods","text":"Table 4. CLIP based methods' performance on OES benchmark. 'Near' represents the average AUROC for Near-OOD datasets, 'Far' indicates the average AUROC for Far-OOD datasets. Method Standard Res Bias Aerial MSRGB IR Near Far Near Far Near Far Near Far Near Far MaxLogits 53.31 43.95 68.99 63.32 64.73 40.46 68.22 9.34 62.73 37.00 MCM 61.79 52.60 59.97 51.94 66.07 67.85 58.90 55.89 54.41 40.43 GLMCM 62.07 52.33 59.20 51.57 65.20 67.42 57.32 56.89 51.75 42.30 CoOp 86.04 94.21 64.09 73.36 61.22 76.40 66.73 90.22 61.30 45.16 LoCoOp 85.71 90.94 66.20 71.67 64.18 76.52 69.64 86.28 61.41 43.33 SCT 85.56 90.78 65.37 70.30 64.14 77.67 68.58 86.41 60.81 42.48 DPM 91.19 99.24 68.60 92.61 60.50 71.26 74.66 93.56 65.11 75.10","title":"CLIP-based Methods"},{"location":"scripts/","text":"Scripts The OpenHAIV framework provides a comprehensive set of shell scripts that help users quickly execute various experiments. These scripts are organized by task type and provide a convenient way to run experiments with pre-configured settings. This document explains the script directory structure, naming conventions, and how to use and customize these scripts. Script Directory Structure The scripts are organized in the following directory structure: scripts/ \u251c\u2500\u2500 sl/ # Supervised Learning scripts \u251c\u2500\u2500 inc/ # Incremental Learning scripts \u251c\u2500\u2500 ood/ # Out-of-Distribution Detection scripts \u2514\u2500\u2500 ncdia_*.sh # Neural Component Decoupling scripts Naming Conventions Scripts follow a consistent naming pattern that indicates: 1. The task type (e.g., sl_ , inc_ , det_ ) 2. The dataset (e.g., oes_ , cifar10_ , cub_ ) 3. The model architecture (e.g., rn18 , coop-b16 ) 4. The algorithm or method (e.g., msp , lwf , savc ) Example: sl_oes_coop-b16.sh indicates a Supervised Learning task on the OES dataset using CoOp-CLIP-B/16 model. Script Types Supervised Learning Scripts ( sl/ ) These scripts train models in a standard supervised learning setting. They typically use the PreTrainer trainer and standard classification losses. Example: # Benchmark: OES # Model: ResNet18 # Method: Cross-Entropy # Task: Supervised Learning python ncdia/train.py \\ --cfg configs/pipeline/supervised_learning/sl_oes_rn18.yaml \\ --opts device='cuda:0' Common supervised learning scripts include: - sl_oes_rn18.sh : Training a ResNet18 model on OES dataset - sl_cifar10_rn18.sh : Training a ResNet18 model on CIFAR10 dataset - sl_oes_coop-b16.sh : Training a CoOp-CLIP-B/16 model on OES dataset Incremental Learning Scripts ( inc/ ) These scripts train models in an incremental learning setting, where new classes are introduced over time. There are two main subtypes: Class-incremental Learning Example: # Benchmark: CUB200 # Model: ResNet18 # Method: LwF # Task: Class-incremental Learning python ncdia/train.py \\ --cfg configs/pipeline/incremental_learning/inc_cub_lwf.yaml \\ --opts device='cuda:0' Few-shot Class-incremental Learning Example: # Benchmark: BM200 # Model: ResNet18 # Method: SAVC # Task: Few-shot Class-incremental Learning python ncdia/train.py \\ --cfg configs/pipeline/incremental_learning/inc_BM200_savc.yaml \\ --opts device='cuda:0' Common incremental learning scripts include: - inc_cub_lwf.sh : Learning without Forgetting on CUB200 dataset - inc_cub_icarl.sh : iCaRL method on CUB200 dataset - inc_BM200_savc.sh : SAVC method on BM200 dataset (few-shot setting) Out-of-Distribution Detection Scripts ( ood/ ) These scripts train and evaluate models for out-of-distribution detection, identifying samples that don't belong to the training distribution. Example: # Benchmark: OES # Model: ResNet50 # Method: MSP # Task: Out-of-Distribution Detection python ncdia/train.py \\ --cfg configs/pipeline/ood_detection/det_oes_rn50_msp.yaml \\ --opts device='cuda:0' Common OOD detection scripts include: - det_oes_rn50_msp.sh : Maximum Softmax Probability method with ResNet50 on OES dataset - det_oes_rn50_mls.sh : Maximum Logit Score method with ResNet50 on OES dataset - det_oes_clip-b16_glmcm.sh : GL-MCM method with CLIP-B/16 on OES dataset Batch Processing Scripts Some scripts are designed to run multiple related experiments in sequence: Example: # Benchmark: OES # Model: Multiple CLIP-based Models # Method: Multiple Detection Methods # Task: Out-of-Distribution Detection (With Training) bash scripts/ood/det_oes_coop-b16_mcm.sh bash scripts/ood/det_oes_locoop-b16_glmcm.sh bash scripts/ood/det_oes_sct-b16_glmcm.sh bash scripts/ood/det_oes_dpm-b16_dpm.sh # More scripts... Customizing Scripts You can customize existing scripts or create new ones by following these steps: Copy an Existing Script : bash cp scripts/sl/sl_oes_rn18.sh scripts/sl/sl_oes_mymodel.sh Modify the Configuration Path : bash # Change this line --cfg configs/pipeline/supervised_learning/sl_oes_rn18.yaml \\ # To point to your custom configuration --cfg configs/pipeline/supervised_learning/sl_oes_mymodel.yaml \\ Update the Script Comments to reflect your experiment: bash # Benchmark: OES # Model: MyModel # Method: MyMethod # Task: Supervised Learning Running Scripts To run a script, simply execute it with bash: bash scripts/sl/sl_oes_rn18.sh You can also override configuration parameters directly from the command line: bash scripts/sl/sl_oes_rn18.sh --opts device='cuda:1' trainer.max_epochs=20 Advanced Usage GPU Selection Most scripts allow specifying the GPU device using the device parameter: python ncdia/train.py \\ --cfg configs/pipeline/supervised_learning/sl_oes_rn18.yaml \\ --opts device='cuda:0' # Use the first GPU To use a different GPU, change cuda:0 to the desired GPU index (e.g., cuda:1 ). Multi-stage Training Some scripts implement multi-stage training, where different phases (e.g., training, testing) are executed sequentially: # Training phase python ncdia/train.py \\ --cfg configs/pipeline/ood_detection/msp/det_oes_rn50_msp_train.yaml \\ --opts device='cuda:0' # Testing phase python ncdia/train.py \\ --cfg configs/pipeline/ood_detection/msp/det_oes_rn50_msp_test.yaml \\ --opts device='cuda:0' Running on Multiple GPUs For multi-GPU training, you can use the CUDA_VISIBLE_DEVICES environment variable: CUDA_VISIBLE_DEVICES=0,1,2,3 python ncdia/train.py \\ --cfg configs/pipeline/supervised_learning/sl_oes_rn18.yaml \\ --opts device='cuda' trainer.distributed=True","title":"scripts"},{"location":"scripts/#scripts","text":"The OpenHAIV framework provides a comprehensive set of shell scripts that help users quickly execute various experiments. These scripts are organized by task type and provide a convenient way to run experiments with pre-configured settings. This document explains the script directory structure, naming conventions, and how to use and customize these scripts.","title":"Scripts"},{"location":"scripts/#script-directory-structure","text":"The scripts are organized in the following directory structure: scripts/ \u251c\u2500\u2500 sl/ # Supervised Learning scripts \u251c\u2500\u2500 inc/ # Incremental Learning scripts \u251c\u2500\u2500 ood/ # Out-of-Distribution Detection scripts \u2514\u2500\u2500 ncdia_*.sh # Neural Component Decoupling scripts","title":"Script Directory Structure"},{"location":"scripts/#naming-conventions","text":"Scripts follow a consistent naming pattern that indicates: 1. The task type (e.g., sl_ , inc_ , det_ ) 2. The dataset (e.g., oes_ , cifar10_ , cub_ ) 3. The model architecture (e.g., rn18 , coop-b16 ) 4. The algorithm or method (e.g., msp , lwf , savc ) Example: sl_oes_coop-b16.sh indicates a Supervised Learning task on the OES dataset using CoOp-CLIP-B/16 model.","title":"Naming Conventions"},{"location":"scripts/#script-types","text":"","title":"Script Types"},{"location":"scripts/#supervised-learning-scripts-sl","text":"These scripts train models in a standard supervised learning setting. They typically use the PreTrainer trainer and standard classification losses. Example: # Benchmark: OES # Model: ResNet18 # Method: Cross-Entropy # Task: Supervised Learning python ncdia/train.py \\ --cfg configs/pipeline/supervised_learning/sl_oes_rn18.yaml \\ --opts device='cuda:0' Common supervised learning scripts include: - sl_oes_rn18.sh : Training a ResNet18 model on OES dataset - sl_cifar10_rn18.sh : Training a ResNet18 model on CIFAR10 dataset - sl_oes_coop-b16.sh : Training a CoOp-CLIP-B/16 model on OES dataset","title":"Supervised Learning Scripts (sl/)"},{"location":"scripts/#incremental-learning-scripts-inc","text":"These scripts train models in an incremental learning setting, where new classes are introduced over time. There are two main subtypes:","title":"Incremental Learning Scripts (inc/)"},{"location":"scripts/#class-incremental-learning","text":"Example: # Benchmark: CUB200 # Model: ResNet18 # Method: LwF # Task: Class-incremental Learning python ncdia/train.py \\ --cfg configs/pipeline/incremental_learning/inc_cub_lwf.yaml \\ --opts device='cuda:0'","title":"Class-incremental Learning"},{"location":"scripts/#few-shot-class-incremental-learning","text":"Example: # Benchmark: BM200 # Model: ResNet18 # Method: SAVC # Task: Few-shot Class-incremental Learning python ncdia/train.py \\ --cfg configs/pipeline/incremental_learning/inc_BM200_savc.yaml \\ --opts device='cuda:0' Common incremental learning scripts include: - inc_cub_lwf.sh : Learning without Forgetting on CUB200 dataset - inc_cub_icarl.sh : iCaRL method on CUB200 dataset - inc_BM200_savc.sh : SAVC method on BM200 dataset (few-shot setting)","title":"Few-shot Class-incremental Learning"},{"location":"scripts/#out-of-distribution-detection-scripts-ood","text":"These scripts train and evaluate models for out-of-distribution detection, identifying samples that don't belong to the training distribution. Example: # Benchmark: OES # Model: ResNet50 # Method: MSP # Task: Out-of-Distribution Detection python ncdia/train.py \\ --cfg configs/pipeline/ood_detection/det_oes_rn50_msp.yaml \\ --opts device='cuda:0' Common OOD detection scripts include: - det_oes_rn50_msp.sh : Maximum Softmax Probability method with ResNet50 on OES dataset - det_oes_rn50_mls.sh : Maximum Logit Score method with ResNet50 on OES dataset - det_oes_clip-b16_glmcm.sh : GL-MCM method with CLIP-B/16 on OES dataset","title":"Out-of-Distribution Detection Scripts (ood/)"},{"location":"scripts/#batch-processing-scripts","text":"Some scripts are designed to run multiple related experiments in sequence: Example: # Benchmark: OES # Model: Multiple CLIP-based Models # Method: Multiple Detection Methods # Task: Out-of-Distribution Detection (With Training) bash scripts/ood/det_oes_coop-b16_mcm.sh bash scripts/ood/det_oes_locoop-b16_glmcm.sh bash scripts/ood/det_oes_sct-b16_glmcm.sh bash scripts/ood/det_oes_dpm-b16_dpm.sh # More scripts...","title":"Batch Processing Scripts"},{"location":"scripts/#customizing-scripts","text":"You can customize existing scripts or create new ones by following these steps: Copy an Existing Script : bash cp scripts/sl/sl_oes_rn18.sh scripts/sl/sl_oes_mymodel.sh Modify the Configuration Path : bash # Change this line --cfg configs/pipeline/supervised_learning/sl_oes_rn18.yaml \\ # To point to your custom configuration --cfg configs/pipeline/supervised_learning/sl_oes_mymodel.yaml \\ Update the Script Comments to reflect your experiment: bash # Benchmark: OES # Model: MyModel # Method: MyMethod # Task: Supervised Learning","title":"Customizing Scripts"},{"location":"scripts/#running-scripts","text":"To run a script, simply execute it with bash: bash scripts/sl/sl_oes_rn18.sh You can also override configuration parameters directly from the command line: bash scripts/sl/sl_oes_rn18.sh --opts device='cuda:1' trainer.max_epochs=20","title":"Running Scripts"},{"location":"scripts/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"scripts/#gpu-selection","text":"Most scripts allow specifying the GPU device using the device parameter: python ncdia/train.py \\ --cfg configs/pipeline/supervised_learning/sl_oes_rn18.yaml \\ --opts device='cuda:0' # Use the first GPU To use a different GPU, change cuda:0 to the desired GPU index (e.g., cuda:1 ).","title":"GPU Selection"},{"location":"scripts/#multi-stage-training","text":"Some scripts implement multi-stage training, where different phases (e.g., training, testing) are executed sequentially: # Training phase python ncdia/train.py \\ --cfg configs/pipeline/ood_detection/msp/det_oes_rn50_msp_train.yaml \\ --opts device='cuda:0' # Testing phase python ncdia/train.py \\ --cfg configs/pipeline/ood_detection/msp/det_oes_rn50_msp_test.yaml \\ --opts device='cuda:0'","title":"Multi-stage Training"},{"location":"scripts/#running-on-multiple-gpus","text":"For multi-GPU training, you can use the CUDA_VISIBLE_DEVICES environment variable: CUDA_VISIBLE_DEVICES=0,1,2,3 python ncdia/train.py \\ --cfg configs/pipeline/supervised_learning/sl_oes_rn18.yaml \\ --opts device='cuda' trainer.distributed=True","title":"Running on Multiple GPUs"}]}